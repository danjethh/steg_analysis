{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjethh/steg_analysis/blob/main/steg_analysis_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import necessary libraries"
      ],
      "metadata": {
        "id": "UpgGQ3tnLc_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import cv2\n",
        "import sys"
      ],
      "metadata": {
        "id": "V6vzSyKvIuYQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load the **dataset**"
      ],
      "metadata": {
        "id": "OsvDucqNLjks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the dataset\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    This function loads the cover and stego image feature datasets,\n",
        "    combines them into a single DataFrame, and adds labels:\n",
        "    - Label '0' for clean images (from steg_features.csv).\n",
        "    - Label '1' for stego images (from steg_lsb_features.csv).\n",
        "    The combined dataset is returned for further processing.\n",
        "    \"\"\"\n",
        "    # URLs for the datasets\n",
        "    url_clean = \"https://raw.githubusercontent.com/Sourish1997/steganalysis/master/Datasets/steg_features.csv\"\n",
        "    url_stego = \"https://raw.githubusercontent.com/Sourish1997/steganalysis/master/Datasets/steg_lsb_features.csv\"\n",
        "\n",
        "    # Load datasets using pandas\n",
        "    print(\"Loading clean dataset...\")\n",
        "    data_clean = pd.read_csv(url_clean, header=None)  # Cover images (clean)\n",
        "    print(f\"Clean dataset shape: {data_clean.shape}\")\n",
        "    print(\"First few rows of clean dataset:\")\n",
        "    print(data_clean.head())  # Display first few rows of clean dataset\n",
        "\n",
        "    print(\"\\nLoading stego dataset...\")\n",
        "    data_stego = pd.read_csv(url_stego, header=None)  # Stego images (with LSB matching)\n",
        "    print(f\"Stego dataset shape: {data_stego.shape}\")\n",
        "    print(\"First few rows of stego dataset:\")\n",
        "    print(data_stego.head())  # Display first few rows of stego dataset\n",
        "\n",
        "    # Add labels to distinguish between clean and stego images\n",
        "    data_clean['label'] = 0  # Label '0' for clean images\n",
        "    data_stego['label'] = 1  # Label '1' for stego images\n",
        "\n",
        "    # Combine the two datasets into one DataFrame\n",
        "    print(\"\\nCombining datasets...\")\n",
        "    data = pd.concat([data_clean, data_stego], axis=0)\n",
        "    print(f\"Combined dataset shape: {data.shape}\")\n",
        "    print(\"First few rows of combined dataset:\")\n",
        "    print(data.head())  # Display first few rows of combined dataset\n",
        "\n",
        "    return data  # Return the combined dataset"
      ],
      "metadata": {
        "id": "nv_snUVYI0vO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Preprocess the data"
      ],
      "metadata": {
        "id": "3HDIRHVjLoa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocess the data\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    This function preprocesses the dataset by performing the following steps:\n",
        "    1. Remove rows with NaN values (caused by overly uniform images).\n",
        "    2. Normalize the features using StandardScaler.\n",
        "    3. Perform Principal Component Analysis (PCA) to reduce dimensionality while retaining most of the variance.\n",
        "    The preprocessed features (X) and labels (y) are returned for training.\n",
        "    \"\"\"\n",
        "    # Separate features and labels\n",
        "    X = data.drop(columns=['label']).values  # Features (all columns except 'label')\n",
        "    y = data['label'].values  # Labels ('0' for clean, '1' for stego')\n",
        "\n",
        "    # Remove rows with NaN values\n",
        "    print(\"\\nRemoving rows with NaN values...\")\n",
        "    nan_mask = ~np.isnan(X).any(axis=1)  # Create a mask for rows without NaN values\n",
        "    X = X[nan_mask]  # Apply the mask to remove NaN rows\n",
        "    y = y[nan_mask]  # Update labels accordingly\n",
        "    print(f\"Dataset shape after removing NaNs: {X.shape}\")\n",
        "    print(\"First few rows of X after removing NaNs:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    # Normalize the features using StandardScaler\n",
        "    print(\"\\nNormalizing features using StandardScaler...\")\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    print(\"First few rows of normalized X:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    # Perform PCA to reduce dimensionality\n",
        "    print(\"\\nPerforming PCA to reduce dimensionality...\")\n",
        "    pca = PCA(n_components=10)  # Retain top 10 principal components\n",
        "    X = pca.fit_transform(X)\n",
        "    print(f\"Explained variance ratio by the first 10 components: {pca.explained_variance_ratio_}\")\n",
        "    print(\"First few rows of X after PCA:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    return X, y  # Return preprocessed features and labels"
      ],
      "metadata": {
        "id": "m5uqq7OuI6MN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Train the classifier"
      ],
      "metadata": {
        "id": "R7fH1i71LrKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train the classifier\n",
        "def train_classifier(X_train, y_train):\n",
        "    \"\"\"\n",
        "    This function trains a Random Forest Classifier on the training data.\n",
        "    Returns the trained classifier.\n",
        "    \"\"\"\n",
        "    print(\"\\nTraining Random Forest Classifier...\")\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=100,  # Number of trees in the forest\n",
        "        max_depth=10,      # Maximum depth of each tree\n",
        "        random_state=42,   # For reproducibility\n",
        "        n_jobs=-1          # Use all available CPU cores for faster training\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf"
      ],
      "metadata": {
        "id": "TQTKPe_sI9-W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Test the classifier on a new image"
      ],
      "metadata": {
        "id": "dGBmrgVgLtF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Test the classifier on a new image\n",
        "def extract_features_from_image(image_path):\n",
        "    \"\"\"\n",
        "    This function extracts CF features from a single image.\n",
        "    Replace this placeholder logic with the actual CF feature extraction code.\n",
        "    \"\"\"\n",
        "    # Load the image and convert to grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image.shape != (512, 512):\n",
        "        raise ValueError(\"Image must be 512x512 pixels.\")\n",
        "\n",
        "    # Placeholder for feature extraction logic\n",
        "    # Simulate feature extraction by generating random features\n",
        "    features = np.random.rand(41)  # Simulated CF features\n",
        "\n",
        "    # Normalize the features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features.reshape(1, -1))\n",
        "\n",
        "    # Apply PCA (using pre-trained PCA model)\n",
        "    pca = PCA(n_components=10)\n",
        "    features = pca.transform(features)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "4p_wZPzSJByT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Main function to train and test the model"
      ],
      "metadata": {
        "id": "juMxyQjdLu5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Main function to train and test the model\n",
        "def main():\n",
        "    \"\"\"\n",
        "    This is the main function that orchestrates the workflow:\n",
        "    1. Load and preprocess the dataset.\n",
        "    2. Train the classifier.\n",
        "    3. Evaluate the classifier on the test set.\n",
        "    4. Optionally test the classifier on a user-provided image.\n",
        "    \"\"\"\n",
        "    # Step 1: Load and preprocess the dataset\n",
        "    data = load_data()\n",
        "    X, y = preprocess_data(data)\n",
        "\n",
        "    # Step 2: Split the dataset into training and testing sets\n",
        "    print(\"\\nSplitting dataset into training and testing sets...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Step 3: Train the classifier\n",
        "    clf = train_classifier(X_train, y_train)\n",
        "\n",
        "    # Step 4: Evaluate the classifier on the test set\n",
        "    print(\"\\nEvaluating classifier on the test set...\")\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Test F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Step 5: Test the classifier on a user-provided image\n",
        "    if len(sys.argv) > 1:\n",
        "        image_path = sys.argv[1]\n",
        "        try:\n",
        "            # Extract features from the image\n",
        "            features = extract_features_from_image(image_path)\n",
        "\n",
        "            # Predict whether the image contains LSB matching steganography\n",
        "            prediction = clf.predict(features)\n",
        "            result = \"Steg Image (LSB Matching Detected)\" if prediction[0] == 1 else \"Cover Image (No LSB Matching)\"\n",
        "            print(f\"\\nPrediction: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {e}\")\n"
      ],
      "metadata": {
        "id": "bLKI0ySWJOot"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Running LSB Matching Detection Tool...\")\n",
        "    main()"
      ],
      "metadata": {
        "id": "cXZp9niLJRhW",
        "outputId": "84c8d946-81c2-40e4-c24a-24586de8cd03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running LSB Matching Detection Tool...\n",
            "Loading clean dataset...\n",
            "Clean dataset shape: (10000, 41)\n",
            "First few rows of clean dataset:\n",
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "4  0.006107  0.932943  0.906990  0.897635  0.886993  0.970490  0.954652   \n",
            "\n",
            "         7         8         9   ...        31        32        33        34  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.001588 -0.004257 -0.000239 -0.266943   \n",
            "1       NaN       NaN       NaN  ...  0.020795 -0.064528  0.015347  0.005049   \n",
            "2  0.866067  0.848226  0.855546  ... -0.008875  0.003529  0.009316 -0.248362   \n",
            "3  0.824739  0.795830  0.856713  ...  0.035087 -0.024424  0.004261 -0.137704   \n",
            "4  0.944758  0.934639  0.934616  ...  0.015832 -0.009279 -0.015531 -0.130431   \n",
            "\n",
            "         35        36        37        38        39        40  \n",
            "0 -0.106837 -0.059703 -0.015162 -0.006729 -0.004329  0.001190  \n",
            "1 -0.145678 -0.189235  0.075486  0.015123 -0.066373  0.015776  \n",
            "2 -0.107545 -0.072559 -0.018520 -0.014878  0.004437  0.008626  \n",
            "3 -0.088573 -0.171084  0.064899  0.052169 -0.024969 -0.000246  \n",
            "4 -0.099206 -0.136827  0.039127  0.025786 -0.013232 -0.022728  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "\n",
            "Loading stego dataset...\n",
            "Stego dataset shape: (10000, 41)\n",
            "First few rows of stego dataset:\n",
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.317249  0.827004  0.760402  0.740601  0.721245  0.909903  0.861059   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503030  0.862545  0.802756  0.775952  0.750876  0.927202  0.888695   \n",
            "3 -0.182986  0.885745  0.833919  0.812366  0.788900  0.909339  0.859644   \n",
            "4  0.005779  0.932725  0.907008  0.897505  0.886902  0.970202  0.954428   \n",
            "\n",
            "         7         8         9   ...        31        32        33        34  \\\n",
            "0  0.834736  0.815029  0.817973  ... -0.004308  0.001464  0.000648 -0.260819   \n",
            "1       NaN       NaN       NaN  ...  0.012889 -0.044616  0.013183 -0.042575   \n",
            "2  0.865893  0.847715  0.855019  ... -0.008937  0.005700  0.006849 -0.249954   \n",
            "3  0.823534  0.794631  0.855730  ...  0.025052 -0.020100  0.004419 -0.156632   \n",
            "4  0.944286  0.934372  0.934324  ...  0.011471 -0.006570 -0.009688 -0.145384   \n",
            "\n",
            "         35        36        37        38        39        40  \n",
            "0 -0.115387 -0.062382 -0.013157 -0.004018  0.000808  0.001451  \n",
            "1 -0.151737 -0.159439  0.056094  0.011527 -0.049579  0.011257  \n",
            "2 -0.110913 -0.068477 -0.015880 -0.013919  0.002656  0.007633  \n",
            "3 -0.101755 -0.147277  0.049512  0.043812 -0.021355 -0.000414  \n",
            "4 -0.115871 -0.119257  0.027204  0.018741 -0.010369 -0.014391  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "\n",
            "Combining datasets...\n",
            "Combined dataset shape: (20000, 42)\n",
            "First few rows of combined dataset:\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "4  0.006107  0.932943  0.906990  0.897635  0.886993  0.970490  0.954652   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.004257 -0.000239 -0.266943 -0.106837   \n",
            "1       NaN       NaN       NaN  ... -0.064528  0.015347  0.005049 -0.145678   \n",
            "2  0.866067  0.848226  0.855546  ...  0.003529  0.009316 -0.248362 -0.107545   \n",
            "3  0.824739  0.795830  0.856713  ... -0.024424  0.004261 -0.137704 -0.088573   \n",
            "4  0.944758  0.934639  0.934616  ... -0.009279 -0.015531 -0.130431 -0.099206   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.059703 -0.015162 -0.006729 -0.004329  0.001190      0  \n",
            "1 -0.189235  0.075486  0.015123 -0.066373  0.015776      0  \n",
            "2 -0.072559 -0.018520 -0.014878  0.004437  0.008626      0  \n",
            "3 -0.171084  0.064899  0.052169 -0.024969 -0.000246      0  \n",
            "4 -0.136827  0.039127  0.025786 -0.013232 -0.022728      0  \n",
            "\n",
            "[5 rows x 42 columns]\n",
            "\n",
            "Removing rows with NaN values...\n",
            "Dataset shape after removing NaNs: (19358, 41)\n",
            "First few rows of X after removing NaNs:\n",
            "[[-3.17326879e-01  8.27515384e-01  7.60604845e-01  7.40965975e-01\n",
            "   7.21417838e-01  9.10647001e-01  8.61356432e-01  8.35196209e-01\n",
            "   8.15543437e-01  8.18339071e-01  7.58361024e-01  7.32744946e-01\n",
            "   7.12313450e-01  8.06705401e-01  7.59407793e-01  1.60797637e-01\n",
            "   2.14583946e-01  1.91990069e-01  1.82255482e-01  1.76242578e-01\n",
            "  -2.84393560e-01 -1.14700224e-01 -5.35871230e-02 -8.57756000e-04\n",
            "  -2.30281000e-04 -4.37930600e-03  3.93935000e-03 -2.54409068e-01\n",
            "  -1.58545180e-01 -4.41293100e-02 -6.17937400e-03 -1.58812800e-03\n",
            "  -4.25697300e-03 -2.38575000e-04 -2.66942911e-01 -1.06837230e-01\n",
            "  -5.97025860e-02 -1.51620180e-02 -6.72895500e-03 -4.32901300e-03\n",
            "   1.18994800e-03]\n",
            " [-5.03110538e-01  8.62969506e-01  8.02899468e-01  7.75813071e-01\n",
            "   7.50999908e-01  9.27451720e-01  8.89261157e-01  8.66067459e-01\n",
            "   8.48225700e-01  8.55546058e-01  8.02765823e-01  7.72049795e-01\n",
            "   7.45870955e-01  8.48025765e-01  8.03066584e-01  7.08126906e-01\n",
            "   8.05188830e-01  7.82544553e-01  7.65448756e-01  7.54554646e-01\n",
            "  -2.69756459e-01 -1.23925267e-01 -6.05388300e-02 -3.14690400e-03\n",
            "   1.97719500e-03  1.90780600e-03  7.21822100e-03 -2.40194334e-01\n",
            "  -1.53606882e-01 -5.73649240e-02 -1.11691540e-02 -8.87453800e-03\n",
            "   3.52904300e-03  9.31591500e-03 -2.48362298e-01 -1.07545294e-01\n",
            "  -7.25590790e-02 -1.85204300e-02 -1.48776580e-02  4.43737100e-03\n",
            "   8.62581800e-03]\n",
            " [-1.82988165e-01  8.87022247e-01  8.35196275e-01  8.13357348e-01\n",
            "   7.89932373e-01  9.11071858e-01  8.61290901e-01  8.24738856e-01\n",
            "   7.95830289e-01  8.56713081e-01  7.89673594e-01  7.51655418e-01\n",
            "   7.19077459e-01  8.21966254e-01  8.14040556e-01  8.52228748e-01\n",
            "   8.86904817e-01  7.98770882e-01  7.58311344e-01  7.24417266e-01\n",
            "  -1.84675668e-01 -1.41335345e-01 -1.04674125e-01  3.33780330e-02\n",
            "   2.05133560e-02 -1.27999090e-02 -1.56012500e-03 -1.38367688e-01\n",
            "  -1.37662126e-01 -1.39336163e-01  5.56987220e-02  3.50867070e-02\n",
            "  -2.44243430e-02  4.26144600e-03 -1.37704042e-01 -8.85728460e-02\n",
            "  -1.71083527e-01  6.48987580e-02  5.21694630e-02 -2.49687250e-02\n",
            "  -2.45669000e-04]\n",
            " [ 6.10712600e-03  9.32942963e-01  9.06989589e-01  8.97635368e-01\n",
            "   8.86992609e-01  9.70490171e-01  9.54651988e-01  9.44757616e-01\n",
            "   9.34638932e-01  9.34616049e-01  9.09627985e-01  8.96681399e-01\n",
            "   8.85960989e-01  9.36205196e-01  9.08038824e-01  9.56642926e-01\n",
            "   9.57538244e-01  8.66155804e-01  7.77389540e-01  7.30494262e-01\n",
            "  -1.51531938e-01 -1.51232997e-01 -9.97532870e-02  2.23439880e-02\n",
            "   1.14565820e-02 -1.15653500e-02 -9.77229600e-03 -1.41366361e-01\n",
            "  -1.36213940e-01 -1.13354946e-01  2.75866550e-02  1.58320820e-02\n",
            "  -9.27909000e-03 -1.55310710e-02 -1.30430947e-01 -9.92061870e-02\n",
            "  -1.36826681e-01  3.91266480e-02  2.57860400e-02 -1.32319900e-02\n",
            "  -2.27284610e-02]\n",
            " [-6.28374420e-02  8.42911712e-01  7.54166316e-01  6.97134807e-01\n",
            "   6.50434952e-01  8.56006610e-01  7.75904023e-01  7.32342295e-01\n",
            "   7.00387704e-01  7.74753406e-01  6.67524383e-01  6.07226568e-01\n",
            "   5.63755555e-01  7.17680051e-01  7.06948794e-01  9.89532533e-01\n",
            "   9.89825393e-01  9.66221156e-01  9.37431269e-01  9.08575756e-01\n",
            "  -1.38280886e-01 -2.10430188e-01 -6.56504700e-02 -7.09406500e-03\n",
            "  -8.08364400e-03 -7.93929600e-03 -6.08440200e-03 -1.42655499e-01\n",
            "  -1.67040442e-01 -8.02435790e-02 -4.59293500e-03 -6.10433900e-03\n",
            "  -1.53024560e-02 -1.07149920e-02 -1.29836173e-01 -1.47590131e-01\n",
            "  -9.29156990e-02 -5.46633200e-03 -6.11160500e-03 -1.63792950e-02\n",
            "  -1.51061280e-02]]\n",
            "\n",
            "Normalizing features using StandardScaler...\n",
            "First few rows of normalized X:\n",
            "[[-4.88272545e-01 -1.24843254e-01 -6.92512840e-02  2.81218583e-02\n",
            "   8.11479657e-02  3.42350181e-01  3.58636454e-01  3.80188014e-01\n",
            "   4.04506139e-01  5.28887177e-02  1.18729460e-01  1.96164528e-01\n",
            "   2.47783051e-01  1.94005376e-01  1.68101451e-02 -7.28024259e+00\n",
            "  -7.27339814e+00 -5.05339646e+00 -4.26411698e+00 -3.79384445e+00\n",
            "  -2.84843326e+00  1.91783086e+00  7.30841389e-01 -3.84903320e-01\n",
            "  -2.20882400e-01  4.73651711e-01  1.83285553e-01 -2.26185187e+00\n",
            "   1.08630736e-02  1.10218498e+00 -5.37986985e-01 -3.38814610e-01\n",
            "   5.79372720e-01  2.33689578e-02 -2.41625949e+00  6.40252439e-01\n",
            "   9.98447674e-01 -6.67860538e-01 -4.49880428e-01  5.86409672e-01\n",
            "   3.22210751e-01]\n",
            " [-1.05536552e+00  1.05924181e-01  1.45508259e-01  1.91330648e-01\n",
            "   2.12534849e-01  4.57574024e-01  5.06030110e-01  5.30049513e-01\n",
            "   5.53978661e-01  2.63196527e-01  3.25469886e-01  3.67118993e-01\n",
            "   3.87751204e-01  3.99862689e-01  2.29837345e-01 -2.22753556e+00\n",
            "  -1.44462857e+00 -8.46104009e-01 -5.97137544e-01 -4.08892407e-01\n",
            "  -2.53920126e+00  1.66876241e+00  5.92396808e-01 -4.35938488e-01\n",
            "  -1.68809141e-01  8.75445580e-01  4.52897822e-01 -1.98722033e+00\n",
            "   1.31022944e-01  8.91815027e-01 -6.18724230e-01 -4.61977767e-01\n",
            "   9.76446056e-01  6.06919565e-01 -2.08738082e+00  6.23820437e-01\n",
            "   8.18372926e-01 -7.13178305e-01 -5.62488028e-01  1.00137836e+00\n",
            "   7.11367816e-01]\n",
            " [-7.82120420e-02  2.62481135e-01  3.09501860e-01  3.67171872e-01\n",
            "   3.85450918e-01  3.45263271e-01  3.58290317e-01  3.29423805e-01\n",
            "   3.14347940e-01  2.69792978e-01  2.64514920e-01  2.78414675e-01\n",
            "   2.75995692e-01  2.70034672e-01  2.83383366e-01 -8.97249692e-01\n",
            "  -6.38161043e-01 -7.30502632e-01 -6.42015878e-01 -5.85291261e-01\n",
            "  -7.41734412e-01  1.19870485e+00 -2.86566075e-01  3.78362855e-01\n",
            "   2.68449665e-01 -6.44883228e-02 -2.68920688e-01 -1.99088985e-02\n",
            "   5.18994631e-01 -4.11055040e-01  4.63232904e-01  2.81105000e-01\n",
            "  -4.49128236e-01  2.98212512e-01 -1.28718826e-01  1.06411298e+00\n",
            "  -5.61611886e-01  4.12464208e-01  3.64041681e-01 -3.90599121e-01\n",
            "   2.47077579e-01]\n",
            " [ 4.98989480e-01  5.61374613e-01  6.74047002e-01  7.61893821e-01\n",
            "   8.16537787e-01  7.52673021e-01  8.51426585e-01  9.12043273e-01\n",
            "   9.49190086e-01  7.10129696e-01  8.23000096e-01  9.09197888e-01\n",
            "   9.72065900e-01  8.39171034e-01  7.42035275e-01  6.66568289e-02\n",
            "   5.89310076e-02 -2.50431646e-01 -5.22056758e-01 -5.49721642e-01\n",
            "  -4.15204721e-02  9.31476519e-01 -1.88566640e-01  1.32365506e-01\n",
            "   5.48048772e-02  1.44093074e-02 -9.44184233e-01 -7.78438685e-02\n",
            "   5.54232246e-01  1.89650696e-03  8.36498741e-03 -4.43584854e-02\n",
            "   3.23253447e-01 -9.10636449e-01  1.56695410e-05  8.17345630e-01\n",
            "  -8.17926314e-02  6.47003021e-02 -5.53023286e-04  1.64975167e-01\n",
            "  -9.29561783e-01]\n",
            " [ 2.88540508e-01 -2.46300515e-02 -1.01944223e-01 -1.77164456e-01\n",
            "  -2.34118011e-01 -3.22990969e-02 -9.27259215e-02 -1.19106368e-01\n",
            "  -1.22159284e-01 -1.93473766e-01 -3.04188926e-01 -3.49771345e-01\n",
            "  -3.71851043e-01 -2.49517322e-01 -2.39156486e-01  3.70279452e-01\n",
            "   3.77577800e-01  4.62464813e-01  4.84247251e-01  4.92617521e-01\n",
            "   2.38429048e-01 -6.66798167e-01  4.90597515e-01 -5.23938051e-01\n",
            "  -4.06139322e-01  2.46141503e-01 -6.40939162e-01 -1.02750276e-01\n",
            "  -1.95845711e-01  5.28176327e-01 -5.12317574e-01 -4.15152725e-01\n",
            "   1.60722090e-02 -6.16489318e-01  1.05432277e-02 -3.05497869e-01\n",
            "   5.33247488e-01 -5.37028812e-01 -4.41349217e-01  1.59932110e-02\n",
            "  -5.30646157e-01]]\n",
            "\n",
            "Performing PCA to reduce dimensionality...\n",
            "Explained variance ratio by the first 10 components: [0.34933847 0.25325881 0.11328639 0.10396695 0.0582953  0.03268833\n",
            " 0.01998358 0.01416521 0.01266699 0.00843501]\n",
            "First few rows of X after PCA:\n",
            "[[ 0.44492168  3.4831905  -8.31895093 -7.87979839 -3.35021102  4.92507816\n",
            "  -1.56227855  0.15574811 -3.23956005 -0.36786936]\n",
            " [-0.06416316  3.50923528 -1.97823227 -0.66285506 -1.30694438  3.94204032\n",
            "  -0.19250202  0.2925629  -1.19120085 -0.2445733 ]\n",
            " [ 1.84034872 -0.54231711 -1.16594215 -0.66919508 -0.09695839  1.62184587\n",
            "  -0.06653646 -0.32517368 -0.2843512   0.20576922]\n",
            " [ 2.85638727  0.97171063 -1.76104404  0.93577446  0.74084318  0.0434043\n",
            "   0.17426312 -0.78725354  0.23751208 -0.15259115]\n",
            " [-1.4111086   0.80276462  0.11114373  0.7112215   0.60683278 -1.23804523\n",
            "   0.02433064 -0.5021851  -0.32250499  0.08020079]]\n",
            "\n",
            "Splitting dataset into training and testing sets...\n",
            "\n",
            "Training Random Forest Classifier...\n",
            "\n",
            "Evaluating classifier on the test set...\n",
            "Test Accuracy: 0.7007\n",
            "Test F1 Score: 0.7326\n",
            "Error processing image: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}