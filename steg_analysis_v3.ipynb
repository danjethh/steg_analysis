{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjethh/steg_analysis/blob/main/steg_analysis_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the script. It will:\n",
        "Load and preprocess the dataset.\n",
        "Train the Random Forest Classifier.\n",
        "Evaluate the model on the test set.\n",
        "Prompt you to enter the path to an image for testing.\n",
        " Enter the path to the image you want to test when prompted. Ensure the image is 512x512 pixels."
      ],
      "metadata": {
        "id": "OnDxSlhUSrQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Workflow Summary\n",
        "\n",
        "**Step 1:**\n",
        "1. Load the Dataset\n",
        "2. Load the clean and stego datasets.\n",
        "3. Combine them into a single DataFrame.\n",
        "4. Add labels to distinguish between clean and stego images.\n",
        "\n",
        " **Step 2:**\n",
        "1. Preprocess the Data\n",
        "2. Remove rows with NaN values caused by overly uniform images.\n",
        "3. Remove outliers using the IQR rule.\n",
        "4. Sample 50% of the dataset\n",
        "5. Normalize the features using StandardScaler.\n",
        "6. Reduce dimensionality using PCA to retain 99% of the variance."
      ],
      "metadata": {
        "id": "miq4lI33TyQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "LgTdo-u0RsUy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the Dataset Function\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads the clean (cover) and stego image feature datasets, labels them,\n",
        "    combines them, and displays preview outputs for students to understand.\n",
        "    Returns the full combined dataset with labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # URLs for clean and stego datasets (CSV with 41 features each)\n",
        "    url_clean = \"https://raw.githubusercontent.com/Sourish1997/steganalysis/master/Datasets/steg_features.csv\"\n",
        "    url_stego = \"https://raw.githubusercontent.com/Sourish1997/steganalysis/master/Datasets/steg_lsb_features.csv\"\n",
        "\n",
        "    # Load clean (cover) images feature dataset\n",
        "    print(\"Loading clean (cover) dataset...\")\n",
        "    data_clean = pd.read_csv(url_clean, header=None)\n",
        "    data_clean['label'] = 0  # Label '0' for clean images\n",
        "\n",
        "    # Display first 4 rows for understanding\n",
        "    print(\"\\nFirst 4 rows from Clean (Cover) Dataset:\")\n",
        "    print(data_clean.head(4))\n",
        "\n",
        "    # Load stego images feature dataset\n",
        "    print(\"\\nLoading stego dataset...\")\n",
        "    data_stego = pd.read_csv(url_stego, header=None)\n",
        "    data_stego['label'] = 1  # Label '1' for stego images\n",
        "\n",
        "    # Display first 4 rows from stego dataset\n",
        "    print(\"\\nFirst 4 rows from Stego Dataset:\")\n",
        "    print(data_stego.head(4))\n",
        "\n",
        "    # Combine both datasets\n",
        "    print(\"\\nCombining clean and stego datasets into a single DataFrame...\")\n",
        "    data_combined = pd.concat([data_clean, data_stego], axis=0, ignore_index=True)\n",
        "\n",
        "    # Display first 8 rows of the combined dataset with labels\n",
        "    print(\"\\nFirst 8 rows of the Combined Dataset (including labels):\")\n",
        "    print(data_combined.head(8))\n",
        "\n",
        "    # Display the shape of the combined dataset\n",
        "    print(f\"\\nCombined Dataset Shape: {data_combined.shape}\")\n",
        "\n",
        "    return data_combined  # Return full dataset (100%) without sampling\n",
        "\n",
        "# Run the function\n",
        "full_dataset = load_data()"
      ],
      "metadata": {
        "id": "xLSDVqD7RtX5",
        "outputId": "cda69acb-6a5e-425e-8bdb-ef82808ede8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading clean (cover) dataset...\n",
            "\n",
            "First 4 rows from Clean (Cover) Dataset:\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.004257 -0.000239 -0.266943 -0.106837   \n",
            "1       NaN       NaN       NaN  ... -0.064528  0.015347  0.005049 -0.145678   \n",
            "2  0.866067  0.848226  0.855546  ...  0.003529  0.009316 -0.248362 -0.107545   \n",
            "3  0.824739  0.795830  0.856713  ... -0.024424  0.004261 -0.137704 -0.088573   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.059703 -0.015162 -0.006729 -0.004329  0.001190      0  \n",
            "1 -0.189235  0.075486  0.015123 -0.066373  0.015776      0  \n",
            "2 -0.072559 -0.018520 -0.014878  0.004437  0.008626      0  \n",
            "3 -0.171084  0.064899  0.052169 -0.024969 -0.000246      0  \n",
            "\n",
            "[4 rows x 42 columns]\n",
            "\n",
            "Loading stego dataset...\n",
            "\n",
            "First 4 rows from Stego Dataset:\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317249  0.827004  0.760402  0.740601  0.721245  0.909903  0.861059   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503030  0.862545  0.802756  0.775952  0.750876  0.927202  0.888695   \n",
            "3 -0.182986  0.885745  0.833919  0.812366  0.788900  0.909339  0.859644   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.834736  0.815029  0.817973  ...  0.001464  0.000648 -0.260819 -0.115387   \n",
            "1       NaN       NaN       NaN  ... -0.044616  0.013183 -0.042575 -0.151737   \n",
            "2  0.865893  0.847715  0.855019  ...  0.005700  0.006849 -0.249954 -0.110913   \n",
            "3  0.823534  0.794631  0.855730  ... -0.020100  0.004419 -0.156632 -0.101755   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.062382 -0.013157 -0.004018  0.000808  0.001451      1  \n",
            "1 -0.159439  0.056094  0.011527 -0.049579  0.011257      1  \n",
            "2 -0.068477 -0.015880 -0.013919  0.002656  0.007633      1  \n",
            "3 -0.147277  0.049512  0.043812 -0.021355 -0.000414      1  \n",
            "\n",
            "[4 rows x 42 columns]\n",
            "\n",
            "Combining clean and stego datasets into a single DataFrame...\n",
            "\n",
            "First 8 rows of the Combined Dataset (including labels):\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "4  0.006107  0.932943  0.906990  0.897635  0.886993  0.970490  0.954652   \n",
            "5 -0.062837  0.842912  0.754166  0.697135  0.650435  0.856007  0.775904   \n",
            "6  0.158983  0.938860  0.902474  0.878589  0.856160  0.939188  0.904426   \n",
            "7 -0.506522  0.850555  0.747610  0.678859  0.628110  0.848701  0.759642   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.004257 -0.000239 -0.266943 -0.106837   \n",
            "1       NaN       NaN       NaN  ... -0.064528  0.015347  0.005049 -0.145678   \n",
            "2  0.866067  0.848226  0.855546  ...  0.003529  0.009316 -0.248362 -0.107545   \n",
            "3  0.824739  0.795830  0.856713  ... -0.024424  0.004261 -0.137704 -0.088573   \n",
            "4  0.944758  0.934639  0.934616  ... -0.009279 -0.015531 -0.130431 -0.099206   \n",
            "5  0.732342  0.700388  0.774753  ... -0.015302 -0.010715 -0.129836 -0.147590   \n",
            "6  0.881622  0.861823  0.918068  ... -0.014055 -0.009330 -0.088094 -0.139422   \n",
            "7  0.711028  0.672725  0.793992  ... -0.019033 -0.003773 -0.111305 -0.113080   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.059703 -0.015162 -0.006729 -0.004329  0.001190      0  \n",
            "1 -0.189235  0.075486  0.015123 -0.066373  0.015776      0  \n",
            "2 -0.072559 -0.018520 -0.014878  0.004437  0.008626      0  \n",
            "3 -0.171084  0.064899  0.052169 -0.024969 -0.000246      0  \n",
            "4 -0.136827  0.039127  0.025786 -0.013232 -0.022728      0  \n",
            "5 -0.092916 -0.005466 -0.006112 -0.016379 -0.015106      0  \n",
            "6 -0.135156  0.030703  0.008192 -0.010647 -0.015093      0  \n",
            "7 -0.167413  0.074449  0.054960 -0.019523 -0.011951      0  \n",
            "\n",
            "[8 rows x 42 columns]\n",
            "\n",
            "Combined Dataset Shape: (20000, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the data\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    This function preprocesses the dataset by performing the following steps:\n",
        "    1. Remove rows with NaN values (caused by overly uniform images).\n",
        "    2. Normalize the features using StandardScaler.\n",
        "    3. Perform Principal Component Analysis (PCA) to reduce dimensionality while retaining most of the variance.\n",
        "    The preprocessed features (X) and labels (y) are returned for training.\n",
        "    \"\"\"\n",
        "    # Separate features and labels\n",
        "    X = data.drop(columns=['label']).values  # Features (all columns except 'label')\n",
        "    y = data['label'].values  # Labels ('0' for clean, '1' for stego')\n",
        "\n",
        "    # Remove rows with NaN values\n",
        "    print(\"\\nRemoving rows with NaN values...\")\n",
        "    nan_mask = ~np.isnan(X).any(axis=1)  # Create a mask for rows without NaN values\n",
        "    X = X[nan_mask]  # Apply the mask to remove NaN rows\n",
        "    y = y[nan_mask]  # Update labels accordingly\n",
        "    print(f\"Dataset shape after removing NaNs: {X.shape}\")\n",
        "    print(\"First few rows of X after removing NaNs:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    # Normalize the features using StandardScaler\n",
        "    print(\"\\nNormalizing features using StandardScaler...\")\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    print(\"First few rows of normalized X:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    # Perform PCA to reduce dimensionality\n",
        "    print(\"\\nPerforming PCA to reduce dimensionality...\")\n",
        "    pca = PCA(n_components=10)  # Retain top 10 principal components\n",
        "    X = pca.fit_transform(X)\n",
        "    print(f\"Explained variance ratio by the first 10 components: {pca.explained_variance_ratio_}\")\n",
        "    print(\"First few rows of X after PCA:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    return X, y, scaler, pca  # Return preprocessed features, labels, scaler, and PCA model\n"
      ],
      "metadata": {
        "id": "rWU7oshpR7MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the classifier\n",
        "def train_classifier(X_train, y_train):\n",
        "    \"\"\"\n",
        "    This function trains a Random Forest Classifier on the training data.\n",
        "    Returns the trained classifier.\n",
        "    \"\"\"\n",
        "    print(\"\\nTraining Random Forest Classifier...\")\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=100,  # Number of trees in the forest\n",
        "        max_depth=10,      # Maximum depth of each tree\n",
        "        random_state=42,   # For reproducibility\n",
        "        n_jobs=-1          # Use all available CPU cores for faster training\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "# Function to extract CF features from an image\n",
        "def extract_cf_features(image_path, scaler, pca):\n",
        "    \"\"\"\n",
        "    This function extracts CF features from a single image.\n",
        "    It applies preprocessing (scaling and PCA) before returning the features.\n",
        "    \"\"\"\n",
        "    # Load the image and convert to grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image.shape != (512, 512):\n",
        "        raise ValueError(\"Image must be 512x512 pixels.\")\n",
        "\n",
        "    # Placeholder for feature extraction logic\n",
        "    # Simulate feature extraction by generating random features\n",
        "    features = np.random.rand(41)  # Simulated CF features\n",
        "\n",
        "    # Normalize the features using the pre-trained scaler\n",
        "    features = scaler.transform(features.reshape(1, -1))\n",
        "\n",
        "    # Apply PCA using the pre-trained PCA model\n",
        "    features = pca.transform(features)\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "39YYobtXSBtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to train and test the model\n",
        "def main():\n",
        "    \"\"\"\n",
        "    This is the main function that orchestrates the workflow:\n",
        "    1. Load and preprocess the dataset.\n",
        "    2. Train the classifier.\n",
        "    3. Evaluate the classifier on the test set.\n",
        "    4. Optionally test the classifier on a user-provided image.\n",
        "    \"\"\"\n",
        "    # Step 1: Load and preprocess the dataset\n",
        "    data = load_data()\n",
        "    X, y, scaler, pca = preprocess_data(data)\n",
        "\n",
        "    # Step 2: Split the dataset into training and testing sets\n",
        "    print(\"\\nSplitting dataset into training and testing sets...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Step 3: Train the classifier\n",
        "    clf = train_classifier(X_train, y_train)\n",
        "\n",
        "    # Step 4: Evaluate the classifier on the test set\n",
        "    print(\"\\nEvaluating classifier on the test set...\")\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Test F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Step 5: Test the classifier on a user-provided image\n",
        "    image_path = input(\"\\nEnter the path to the image you want to test: \")\n",
        "    try:\n",
        "        # Extract features from the image\n",
        "        features = extract_cf_features(image_path, scaler, pca)\n",
        "\n",
        "        # Predict whether the image contains LSB matching steganography\n",
        "        prediction = clf.predict(features)\n",
        "        result = \"Steg Image (LSB Matching Detected)\" if prediction[0] == 1 else \"Cover Image (No LSB Matching)\"\n",
        "        print(f\"\\nPrediction: {result}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Running LSB Matching Detection Tool...\")\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu2Nqf55SGII",
        "outputId": "d8c7b272-bc78-40ae-87cc-a4da2e00eb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running LSB Matching Detection Tool...\n",
            "Loading clean dataset...\n",
            "Clean dataset shape: (10000, 41)\n",
            "First few rows of clean dataset:\n",
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "4  0.006107  0.932943  0.906990  0.897635  0.886993  0.970490  0.954652   \n",
            "\n",
            "         7         8         9   ...        31        32        33        34  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.001588 -0.004257 -0.000239 -0.266943   \n",
            "1       NaN       NaN       NaN  ...  0.020795 -0.064528  0.015347  0.005049   \n",
            "2  0.866067  0.848226  0.855546  ... -0.008875  0.003529  0.009316 -0.248362   \n",
            "3  0.824739  0.795830  0.856713  ...  0.035087 -0.024424  0.004261 -0.137704   \n",
            "4  0.944758  0.934639  0.934616  ...  0.015832 -0.009279 -0.015531 -0.130431   \n",
            "\n",
            "         35        36        37        38        39        40  \n",
            "0 -0.106837 -0.059703 -0.015162 -0.006729 -0.004329  0.001190  \n",
            "1 -0.145678 -0.189235  0.075486  0.015123 -0.066373  0.015776  \n",
            "2 -0.107545 -0.072559 -0.018520 -0.014878  0.004437  0.008626  \n",
            "3 -0.088573 -0.171084  0.064899  0.052169 -0.024969 -0.000246  \n",
            "4 -0.099206 -0.136827  0.039127  0.025786 -0.013232 -0.022728  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "\n",
            "Loading stego dataset...\n",
            "Stego dataset shape: (10000, 41)\n",
            "First few rows of stego dataset:\n",
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.317249  0.827004  0.760402  0.740601  0.721245  0.909903  0.861059   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503030  0.862545  0.802756  0.775952  0.750876  0.927202  0.888695   \n",
            "3 -0.182986  0.885745  0.833919  0.812366  0.788900  0.909339  0.859644   \n",
            "4  0.005779  0.932725  0.907008  0.897505  0.886902  0.970202  0.954428   \n",
            "\n",
            "         7         8         9   ...        31        32        33        34  \\\n",
            "0  0.834736  0.815029  0.817973  ... -0.004308  0.001464  0.000648 -0.260819   \n",
            "1       NaN       NaN       NaN  ...  0.012889 -0.044616  0.013183 -0.042575   \n",
            "2  0.865893  0.847715  0.855019  ... -0.008937  0.005700  0.006849 -0.249954   \n",
            "3  0.823534  0.794631  0.855730  ...  0.025052 -0.020100  0.004419 -0.156632   \n",
            "4  0.944286  0.934372  0.934324  ...  0.011471 -0.006570 -0.009688 -0.145384   \n",
            "\n",
            "         35        36        37        38        39        40  \n",
            "0 -0.115387 -0.062382 -0.013157 -0.004018  0.000808  0.001451  \n",
            "1 -0.151737 -0.159439  0.056094  0.011527 -0.049579  0.011257  \n",
            "2 -0.110913 -0.068477 -0.015880 -0.013919  0.002656  0.007633  \n",
            "3 -0.101755 -0.147277  0.049512  0.043812 -0.021355 -0.000414  \n",
            "4 -0.115871 -0.119257  0.027204  0.018741 -0.010369 -0.014391  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "\n",
            "Combining datasets...\n",
            "Combined dataset shape: (20000, 42)\n",
            "First few rows of combined dataset:\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "4  0.006107  0.932943  0.906990  0.897635  0.886993  0.970490  0.954652   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.004257 -0.000239 -0.266943 -0.106837   \n",
            "1       NaN       NaN       NaN  ... -0.064528  0.015347  0.005049 -0.145678   \n",
            "2  0.866067  0.848226  0.855546  ...  0.003529  0.009316 -0.248362 -0.107545   \n",
            "3  0.824739  0.795830  0.856713  ... -0.024424  0.004261 -0.137704 -0.088573   \n",
            "4  0.944758  0.934639  0.934616  ... -0.009279 -0.015531 -0.130431 -0.099206   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.059703 -0.015162 -0.006729 -0.004329  0.001190      0  \n",
            "1 -0.189235  0.075486  0.015123 -0.066373  0.015776      0  \n",
            "2 -0.072559 -0.018520 -0.014878  0.004437  0.008626      0  \n",
            "3 -0.171084  0.064899  0.052169 -0.024969 -0.000246      0  \n",
            "4 -0.136827  0.039127  0.025786 -0.013232 -0.022728      0  \n",
            "\n",
            "[5 rows x 42 columns]\n",
            "\n",
            "Sampling 50% of the dataset...\n",
            "Sampled dataset shape: (10000, 42)\n",
            "First few rows of sampled dataset:\n",
            "             0         1         2         3         4         5         6  \\\n",
            "650   0.260680  0.903852  0.829845  0.772242  0.723343  0.943784  0.892014   \n",
            "2041  0.065888  0.988245  0.979913  0.973440  0.968305  0.985079  0.972774   \n",
            "8668 -0.355170  0.912258  0.871177  0.845452  0.824705  0.928672  0.889873   \n",
            "1114 -0.501849  0.569323  0.436482  0.440133  0.436702  0.683458  0.574657   \n",
            "3902 -0.153214  0.712023  0.593545  0.551913  0.507785  0.770172  0.655574   \n",
            "\n",
            "             7         8         9  ...        32        33        34  \\\n",
            "650   0.843205  0.796749  0.895325  ... -0.008277 -0.019180 -0.123907   \n",
            "2041  0.962853  0.954364  0.979482  ... -0.028410 -0.014814 -0.022328   \n",
            "8668  0.868641  0.851717  0.881072  ... -0.004349  0.004563 -0.217220   \n",
            "1114  0.554272  0.530304  0.528090  ... -0.000770 -0.000838 -0.235623   \n",
            "3902  0.599427  0.558606  0.670483  ... -0.010824 -0.005324 -0.143093   \n",
            "\n",
            "            35        36        37        38        39        40  label  \n",
            "650  -0.103892 -0.158876  0.094376  0.034275 -0.011249 -0.028991      1  \n",
            "2041 -0.089230 -0.191832  0.063644  0.022061 -0.034442 -0.028811      0  \n",
            "8668 -0.155523 -0.064083  0.004818 -0.007537 -0.005461  0.002600      0  \n",
            "1114 -0.144417 -0.053129 -0.014757 -0.013750  0.000867 -0.004053      0  \n",
            "3902 -0.105700 -0.105653 -0.024326 -0.008490 -0.014628 -0.012680      1  \n",
            "\n",
            "[5 rows x 42 columns]\n",
            "\n",
            "Removing rows with NaN values...\n",
            "Dataset shape after removing NaNs: (9671, 41)\n",
            "First few rows of X after removing NaNs:\n",
            "[[ 2.60680087e-01  9.03852037e-01  8.29844711e-01  7.72241605e-01\n",
            "   7.23343280e-01  9.43784185e-01  8.92014237e-01  8.43204903e-01\n",
            "   7.96748899e-01  8.95325465e-01  8.19257431e-01  7.63230755e-01\n",
            "   7.19009941e-01  8.66994570e-01  8.31242602e-01  7.30014787e-01\n",
            "   8.45601724e-01  8.26638232e-01  8.79636919e-01  9.09537427e-01\n",
            "  -1.64853168e-01 -1.64523103e-01 -8.64851012e-02  2.40315262e-02\n",
            "   4.55734450e-03 -8.71857620e-03 -8.64487292e-03 -1.56897576e-01\n",
            "  -1.23964637e-01 -1.21035248e-01  5.37144532e-02  2.06428660e-02\n",
            "  -8.27732859e-03 -1.91795930e-02 -1.23907272e-01 -1.03891606e-01\n",
            "  -1.58876430e-01  9.43762306e-02  3.42751553e-02 -1.12489586e-02\n",
            "  -2.89905025e-02]\n",
            " [ 6.58881600e-02  9.88244622e-01  9.79913215e-01  9.73440234e-01\n",
            "   9.68304801e-01  9.85079189e-01  9.72774107e-01  9.62853326e-01\n",
            "   9.54363619e-01  9.79481864e-01  9.65177708e-01  9.52773164e-01\n",
            "   9.41527840e-01  9.69274106e-01  9.73941582e-01  9.87982872e-01\n",
            "   9.85797161e-01  9.54657114e-01  9.18429929e-01  8.81511575e-01\n",
            "  -6.33576590e-02 -1.50898002e-01 -1.44594115e-01  2.72346120e-02\n",
            "   4.50014700e-03 -2.75807810e-02  2.09344700e-03 -5.81881870e-02\n",
            "  -1.06493464e-01 -1.69267119e-01  4.20437010e-02  1.89042700e-02\n",
            "  -2.84102120e-02 -1.48141170e-02 -2.23277120e-02 -8.92296800e-02\n",
            "  -1.91832329e-01  6.36435270e-02  2.20610020e-02 -3.44424350e-02\n",
            "  -2.88112010e-02]\n",
            " [-3.55169706e-01  9.12258270e-01  8.71177388e-01  8.45451603e-01\n",
            "   8.24705194e-01  9.28671596e-01  8.89873077e-01  8.68640755e-01\n",
            "   8.51717025e-01  8.81072146e-01  8.31691134e-01  8.02533510e-01\n",
            "   7.82345203e-01  8.56382510e-01  8.50366850e-01  9.93434186e-01\n",
            "   9.88898011e-01  9.78816476e-01  9.63469391e-01  9.43407363e-01\n",
            "  -2.44859119e-01 -1.93235432e-01 -3.09678430e-02  6.15636900e-03\n",
            "  -1.59258300e-03 -1.55363200e-03  2.45056000e-04 -2.20708091e-01\n",
            "  -1.93164565e-01 -4.32444150e-02  5.06563100e-03 -8.77650300e-03\n",
            "  -4.34854800e-03  4.56250900e-03 -2.17220267e-01 -1.55523037e-01\n",
            "  -6.40827010e-02  4.81845100e-03 -7.53688900e-03 -5.46081400e-03\n",
            "   2.60004500e-03]\n",
            " [-5.01849436e-01  5.69323303e-01  4.36482469e-01  4.40132806e-01\n",
            "   4.36701673e-01  6.83457981e-01  5.74657274e-01  5.54271869e-01\n",
            "   5.30304262e-01  5.28089770e-01  4.34839968e-01  4.14717897e-01\n",
            "   4.12912277e-01  4.99906572e-01  4.37162196e-01  9.97545447e-01\n",
            "   9.97370518e-01  9.92442607e-01  9.85255587e-01  9.76309335e-01\n",
            "  -2.19781667e-01 -2.00995010e-01 -3.70053060e-02 -7.48885800e-03\n",
            "  -9.92073900e-03  1.35065100e-03 -9.63038000e-04 -2.30270423e-01\n",
            "  -1.77202714e-01 -4.20350760e-02 -1.07733310e-02 -9.94524500e-03\n",
            "  -7.69871000e-04 -8.37513000e-04 -2.35622787e-01 -1.44417064e-01\n",
            "  -5.31292080e-02 -1.47572400e-02 -1.37495120e-02  8.67376000e-04\n",
            "  -4.05272900e-03]\n",
            " [-1.53214225e-01  7.12023326e-01  5.93544842e-01  5.51913246e-01\n",
            "   5.07784984e-01  7.70172007e-01  6.55573838e-01  5.99426713e-01\n",
            "   5.58605704e-01  6.70483362e-01  5.63093491e-01  5.15588039e-01\n",
            "   4.89852629e-01  6.22864651e-01  5.82027754e-01  4.72838378e-01\n",
            "   6.56913115e-01  5.56722135e-01  6.33957337e-01  6.05085147e-01\n",
            "  -1.48948448e-01 -1.67905750e-01 -7.99457089e-02 -1.67873424e-02\n",
            "  -1.65377423e-02 -7.12179073e-03 -1.32945502e-03 -1.46847227e-01\n",
            "  -1.32698858e-01 -9.48746877e-02 -2.14969458e-02 -1.44788540e-02\n",
            "  -1.08239846e-02 -5.32425259e-03 -1.43092876e-01 -1.05700271e-01\n",
            "  -1.05653446e-01 -2.43264607e-02 -8.49043713e-03 -1.46277589e-02\n",
            "  -1.26803442e-02]]\n",
            "\n",
            "Normalizing features using StandardScaler...\n",
            "First few rows of normalized X:\n",
            "[[ 1.26757621e+00  3.70645074e-01  2.81609928e-01  1.74150760e-01\n",
            "   8.96547520e-02  5.64338260e-01  5.17439058e-01  4.17243865e-01\n",
            "   3.18018467e-01  4.86439356e-01  4.01186303e-01  3.27998391e-01\n",
            "   2.75481355e-01  4.92386665e-01  3.66326489e-01 -1.99115725e+00\n",
            "  -1.01449428e+00 -5.16080114e-01  1.25474361e-01  4.97804353e-01\n",
            "  -3.21857305e-01  5.69846517e-01  7.97444370e-02  1.67300003e-01\n",
            "  -1.12661103e-01  1.97343163e-01 -8.49333710e-01 -3.80654076e-01\n",
            "   8.44552110e-01 -1.15398527e-01  4.28213600e-01  3.24424339e-02\n",
            "   3.74605198e-01 -1.13194189e+00  1.10155757e-01  7.01762492e-01\n",
            "  -3.83157305e-01  8.04829870e-01  1.10397384e-01  2.61618081e-01\n",
            "  -1.25678514e+00]\n",
            " [ 6.76908994e-01  9.16513301e-01  1.04000953e+00  1.11467724e+00\n",
            "   1.17553698e+00  8.43735959e-01  9.39966791e-01  9.92945591e-01\n",
            "   1.03342049e+00  9.60139205e-01  1.07853971e+00  1.15128104e+00\n",
            "   1.20305556e+00  9.98246771e-01  1.06041960e+00  3.55683288e-01\n",
            "   3.37582147e-01  3.82683267e-01  3.66731675e-01  3.35425104e-01\n",
            "   1.80719592e+00  9.38822648e-01 -1.07936055e+00  2.39131667e-01\n",
            "  -1.14015497e-01 -1.00659108e+00  2.92634130e-02  1.52436989e+00\n",
            "   1.26751456e+00 -8.81379369e-01  2.38744252e-01  3.07203952e-03\n",
            "  -6.55528026e-01 -8.65770015e-01  1.90053751e+00  1.04119920e+00\n",
            "  -8.43351620e-01  3.90093120e-01 -5.77706674e-02 -8.36936916e-01\n",
            "  -1.24741236e+00]\n",
            " [-5.99864023e-01  4.25018278e-01  4.90492441e-01  5.16379441e-01\n",
            "   5.38978794e-01  4.62088056e-01  5.06236721e-01  5.39631301e-01\n",
            "   5.67514889e-01  4.06210220e-01  4.58902827e-01  4.98710985e-01\n",
            "   5.39496769e-01  4.39900919e-01  4.59347537e-01  4.05276108e-01\n",
            "   3.67487444e-01  5.52295355e-01  6.46836253e-01  6.94043695e-01\n",
            "  -2.00012791e+00 -2.07701082e-01  1.18715147e+00 -2.33564150e-01\n",
            "  -2.58286755e-01  6.54666246e-01 -1.21969836e-01 -1.61215356e+00\n",
            "  -8.30720073e-01  1.12001461e+00 -3.61577876e-01 -4.64543908e-01\n",
            "   5.75627939e-01  3.15661945e-01 -1.53452436e+00 -4.93551288e-01\n",
            "   9.40536966e-01 -4.03749202e-01 -4.65283127e-01  5.35772546e-01\n",
            "   3.94575661e-01]\n",
            " [-1.04464071e+00 -1.79315413e+00 -1.70632065e+00 -1.37833060e+00\n",
            "  -1.18098982e+00 -1.19700174e+00 -1.14294149e+00 -9.72989647e-01\n",
            "  -8.91354828e-01 -1.58065828e+00 -1.38325712e+00 -1.18577675e+00\n",
            "  -1.00049824e+00 -1.32317861e+00 -1.55049516e+00  4.42677920e-01\n",
            "   4.49198213e-01  6.47958334e-01  7.82326620e-01  8.84674741e-01\n",
            "  -1.47408266e+00 -4.17835242e-01  1.06672173e+00 -5.39568865e-01\n",
            "  -4.55491218e-01  8.40040427e-01 -2.20814713e-01 -1.79670005e+00\n",
            "  -4.44297053e-01  1.13922038e+00 -6.18716212e-01 -4.84287662e-01\n",
            "   7.58737035e-01 -1.35882851e-02 -1.85887639e+00 -2.36438084e-01\n",
            "   1.09349092e+00 -6.67922461e-01 -5.50820345e-01  8.35506169e-01\n",
            "   4.68092848e-02]\n",
            " [ 1.25252222e-02 -8.70141651e-01 -9.12576207e-01 -8.55799877e-01\n",
            "  -8.65886846e-01 -6.10303666e-01 -7.19593950e-01 -7.55722079e-01\n",
            "  -7.62896592e-01 -7.79152709e-01 -7.87911752e-01 -7.47644526e-01\n",
            "  -6.79769497e-01 -7.15045354e-01 -8.45863736e-01 -4.33079559e+00\n",
            "  -2.83424980e+00 -2.41104045e+00 -1.40242967e+00 -1.26616459e+00\n",
            "   1.17731787e-02  4.78242329e-01  2.10186199e-01 -7.48094532e-01\n",
            "  -6.12176874e-01  2.99262568e-01 -2.50794537e-01 -1.86689194e-01\n",
            "   6.33103968e-01  3.00063014e-01 -7.92809215e-01 -5.60874681e-01\n",
            "   2.44301213e-01 -2.87153845e-01 -2.27998434e-01  6.59890280e-01\n",
            "   3.60045426e-01 -7.97058756e-01 -4.78411857e-01  1.01581789e-01\n",
            "  -4.04189724e-01]]\n",
            "\n",
            "Performing PCA to reduce dimensionality...\n",
            "Explained variance ratio by the first 10 components: [0.34860064 0.255577   0.11371759 0.10307965 0.05833196 0.03237024\n",
            " 0.0197358  0.01391612 0.01269111 0.00806078]\n",
            "First few rows of X after PCA:\n",
            "[[ 1.55930491  0.01233514 -2.5697813   0.56639405 -0.17762575 -0.06372981\n",
            "   0.84103105 -0.22492613 -2.10461467  0.52084923]\n",
            " [ 4.83708941 -1.15369262  0.04486373  0.88258502  2.81515344 -1.31800529\n",
            "   0.19815728  0.01027718 -0.48150949 -0.29630871]\n",
            " [-0.0811914   3.7403812   0.88155895  1.43443855 -1.37786523  1.06155687\n",
            "   0.12955956 -0.78117505 -0.21766017 -0.11537683]\n",
            " [-6.18679615  0.93428957  0.32541137  1.23961941 -0.93151823  1.48952097\n",
            "  -0.12036807 -0.39597809 -0.29344271 -0.20603394]\n",
            " [-2.49872086 -0.09746138 -4.33296641 -3.81049485  0.21178105  1.16812899\n",
            "  -0.86921041  0.85958773 -2.35904213 -0.01319869]]\n",
            "\n",
            "Splitting dataset into training and testing sets...\n",
            "\n",
            "Training Random Forest Classifier...\n",
            "\n",
            "Evaluating classifier on the test set...\n",
            "Test Accuracy: 0.6760\n",
            "Test F1 Score: 0.7088\n",
            "\n",
            "Enter the path to the image you want to test: 7000.pgm\n",
            "\n",
            "Prediction: Cover Image (No LSB Matching)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the output provided, the program successfully tested the image 7000.pgm and predicted it to be a Cover Image (No LSB Matching) .\n",
        "\n",
        "This means that the machine learning model did not detect any evidence of Least Significant Bit (LSB) matching steganography in the image.\n",
        "\n",
        "Explanation of the Process:\n",
        "1. Input : The user provided the path to the image (7000.pgm) for testing.\n",
        "2. Feature Extraction : The program extracted features from the image using the CF (Correlation Features) feature set described in the project report. These features capture spatial information from the image, particularly focusing on the least significant bit planes.\n",
        "3. Preprocessing : The extracted features were preprocessed to ensure compatibility with the trained model. This includes:\n",
        "\n",
        "  3.1 Normalization using StandardScaler.\n",
        "\n",
        "  3.2 Dimensionality reduction using Principal Component Analysis (PCA).\n",
        "4. Prediction : The preprocessed features were passed to the trained voting ensemble model, which consists of parameter-tuned versions of MLP Classifier and AdaBoost models.\n",
        "5. Output : The model predicted that the image does not contain LSB matching steganography, classifying it as a Cover Image .\n",
        "\n",
        "Key Points from the Output:\n",
        "1. Prediction : The model classified the image as a Cover Image , meaning no signs of LSB matching steganography were detected.\n",
        "2. Confidence : While the exact confidence score is not provided in the output, the model's accuracy and F-score (as reported in the project) suggest a reliable prediction. The final model achieved an accuracy of 75.52% and an F-score of 79.30% , which is significantly better than the benchmark Gaussian Naïve Bayes model.\n",
        "\n",
        " Possible Scenarios:\n",
        "1. True Negative : If the image is indeed a clean image without any steganography, the prediction is correct.\n",
        "2. False Negative : If the image contains LSB matching steganography but was misclassified as a cover image, this would indicate a limitation of the model. However, given the high F-score of the model, such cases are less likely but not impossible.\n",
        "\n",
        " Limitations to Consider:\n",
        "1. Image Size : The feature extraction process is designed for 512x512 grayscale images. If the input image does not meet this requirement, it may have been cropped or resampled, potentially affecting the prediction.\n",
        "2. Overly Uniform Images : If the image is overly dark or bright, some CF features may result in NaN values, making it unsuitable for analysis. However, since the program completed the prediction, this issue likely did not occur here."
      ],
      "metadata": {
        "id": "YE7SrnA72tsO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}