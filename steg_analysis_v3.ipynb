{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjethh/steg_analysis/blob/main/steg_analysis_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the script. It will:\n",
        "Load and preprocess the dataset.\n",
        "Train the Random Forest Classifier.\n",
        "Evaluate the model on the test set.\n",
        "Prompt you to enter the path to an image for testing.\n",
        " Enter the path to the image you want to test when prompted. Ensure the image is 512x512 pixels."
      ],
      "metadata": {
        "id": "OnDxSlhUSrQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Workflow Summary\n",
        "\n",
        "**Step 1:**\n",
        "1. Load the Dataset\n",
        "2. Load the clean and stego datasets.\n",
        "3. Combine them into a single DataFrame.\n",
        "4. Add labels to distinguish between clean and stego images.\n",
        "\n",
        " **Step 2:**\n",
        "1. Preprocess the Data\n",
        "2. Remove rows with NaN values caused by overly uniform images.\n",
        "3. Remove outliers using the IQR rule.\n",
        "4. Sample 50% of the dataset\n",
        "5. Normalize the features using StandardScaler.\n",
        "6. Reduce dimensionality using PCA to retain 99% of the variance."
      ],
      "metadata": {
        "id": "miq4lI33TyQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets"
      ],
      "metadata": {
        "id": "e-RQEgFpEQqj",
        "outputId": "552f501f-8d99-4466-cef4-be1af831b31b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "LgTdo-u0RsUy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the Dataset Function\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads the clean (cover) and stego image feature datasets, labels them,\n",
        "    combines them, and displays preview outputs for students to understand.\n",
        "    Returns the full combined dataset with labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # URLs for clean and stego datasets (CSV with 41 features each)\n",
        "    url_clean = \"https://raw.githubusercontent.com/Sourish1997/steganalysis/master/Datasets/steg_features.csv\"\n",
        "    url_stego = \"https://raw.githubusercontent.com/Sourish1997/steganalysis/master/Datasets/steg_lsb_features.csv\"\n",
        "\n",
        "    # Load clean (cover) images feature dataset\n",
        "    print(\"Loading clean (cover) dataset...\")\n",
        "    data_clean = pd.read_csv(url_clean, header=None)\n",
        "    data_clean['label'] = 0  # Label '0' for clean images\n",
        "\n",
        "    # Display first 4 rows for understanding\n",
        "    print(\"\\nFirst 4 rows from Clean (Cover) Dataset:\")\n",
        "    print(data_clean.head(4))\n",
        "\n",
        "    # Load stego images feature dataset\n",
        "    print(\"\\nLoading stego dataset...\")\n",
        "    data_stego = pd.read_csv(url_stego, header=None)\n",
        "    data_stego['label'] = 1  # Label '1' for stego images\n",
        "\n",
        "    # Display first 4 rows from stego dataset\n",
        "    print(\"\\nFirst 4 rows from Stego Dataset:\")\n",
        "    print(data_stego.head(4))\n",
        "\n",
        "    # Combine both datasets\n",
        "    print(\"\\nCombining clean and stego datasets into a single DataFrame...\")\n",
        "    data_combined = pd.concat([data_clean, data_stego], axis=0, ignore_index=True)\n",
        "\n",
        "    # Display first 8 rows of the combined dataset with labels\n",
        "    print(\"\\nFirst 8 rows of the Combined Dataset (including labels):\")\n",
        "    print(data_combined.head(8))\n",
        "\n",
        "    # Display the shape of the combined dataset\n",
        "    print(f\"\\nCombined Dataset Shape: {data_combined.shape}\")\n",
        "\n",
        "    return data_combined  # Return full dataset (100%) without sampling\n",
        "\n",
        "# Run the function\n",
        "full_dataset = load_data()"
      ],
      "metadata": {
        "id": "xLSDVqD7RtX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c9f56e-4985-4898-bda6-095ff995613a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading clean (cover) dataset...\n",
            "\n",
            "First 4 rows from Clean (Cover) Dataset:\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.004257 -0.000239 -0.266943 -0.106837   \n",
            "1       NaN       NaN       NaN  ... -0.064528  0.015347  0.005049 -0.145678   \n",
            "2  0.866067  0.848226  0.855546  ...  0.003529  0.009316 -0.248362 -0.107545   \n",
            "3  0.824739  0.795830  0.856713  ... -0.024424  0.004261 -0.137704 -0.088573   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.059703 -0.015162 -0.006729 -0.004329  0.001190      0  \n",
            "1 -0.189235  0.075486  0.015123 -0.066373  0.015776      0  \n",
            "2 -0.072559 -0.018520 -0.014878  0.004437  0.008626      0  \n",
            "3 -0.171084  0.064899  0.052169 -0.024969 -0.000246      0  \n",
            "\n",
            "[4 rows x 42 columns]\n",
            "\n",
            "Loading stego dataset...\n",
            "\n",
            "First 4 rows from Stego Dataset:\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317249  0.827004  0.760402  0.740601  0.721245  0.909903  0.861059   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503030  0.862545  0.802756  0.775952  0.750876  0.927202  0.888695   \n",
            "3 -0.182986  0.885745  0.833919  0.812366  0.788900  0.909339  0.859644   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.834736  0.815029  0.817973  ...  0.001464  0.000648 -0.260819 -0.115387   \n",
            "1       NaN       NaN       NaN  ... -0.044616  0.013183 -0.042575 -0.151737   \n",
            "2  0.865893  0.847715  0.855019  ...  0.005700  0.006849 -0.249954 -0.110913   \n",
            "3  0.823534  0.794631  0.855730  ... -0.020100  0.004419 -0.156632 -0.101755   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.062382 -0.013157 -0.004018  0.000808  0.001451      1  \n",
            "1 -0.159439  0.056094  0.011527 -0.049579  0.011257      1  \n",
            "2 -0.068477 -0.015880 -0.013919  0.002656  0.007633      1  \n",
            "3 -0.147277  0.049512  0.043812 -0.021355 -0.000414      1  \n",
            "\n",
            "[4 rows x 42 columns]\n",
            "\n",
            "Combining clean and stego datasets into a single DataFrame...\n",
            "\n",
            "First 8 rows of the Combined Dataset (including labels):\n",
            "          0         1         2         3         4         5         6  \\\n",
            "0 -0.317327  0.827515  0.760605  0.740966  0.721418  0.910647  0.861356   \n",
            "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "2 -0.503111  0.862970  0.802899  0.775813  0.751000  0.927452  0.889261   \n",
            "3 -0.182988  0.887022  0.835196  0.813357  0.789932  0.911072  0.861291   \n",
            "4  0.006107  0.932943  0.906990  0.897635  0.886993  0.970490  0.954652   \n",
            "5 -0.062837  0.842912  0.754166  0.697135  0.650435  0.856007  0.775904   \n",
            "6  0.158983  0.938860  0.902474  0.878589  0.856160  0.939188  0.904426   \n",
            "7 -0.506522  0.850555  0.747610  0.678859  0.628110  0.848701  0.759642   \n",
            "\n",
            "          7         8         9  ...        32        33        34        35  \\\n",
            "0  0.835196  0.815543  0.818339  ... -0.004257 -0.000239 -0.266943 -0.106837   \n",
            "1       NaN       NaN       NaN  ... -0.064528  0.015347  0.005049 -0.145678   \n",
            "2  0.866067  0.848226  0.855546  ...  0.003529  0.009316 -0.248362 -0.107545   \n",
            "3  0.824739  0.795830  0.856713  ... -0.024424  0.004261 -0.137704 -0.088573   \n",
            "4  0.944758  0.934639  0.934616  ... -0.009279 -0.015531 -0.130431 -0.099206   \n",
            "5  0.732342  0.700388  0.774753  ... -0.015302 -0.010715 -0.129836 -0.147590   \n",
            "6  0.881622  0.861823  0.918068  ... -0.014055 -0.009330 -0.088094 -0.139422   \n",
            "7  0.711028  0.672725  0.793992  ... -0.019033 -0.003773 -0.111305 -0.113080   \n",
            "\n",
            "         36        37        38        39        40  label  \n",
            "0 -0.059703 -0.015162 -0.006729 -0.004329  0.001190      0  \n",
            "1 -0.189235  0.075486  0.015123 -0.066373  0.015776      0  \n",
            "2 -0.072559 -0.018520 -0.014878  0.004437  0.008626      0  \n",
            "3 -0.171084  0.064899  0.052169 -0.024969 -0.000246      0  \n",
            "4 -0.136827  0.039127  0.025786 -0.013232 -0.022728      0  \n",
            "5 -0.092916 -0.005466 -0.006112 -0.016379 -0.015106      0  \n",
            "6 -0.135156  0.030703  0.008192 -0.010647 -0.015093      0  \n",
            "7 -0.167413  0.074449  0.054960 -0.019523 -0.011951      0  \n",
            "\n",
            "[8 rows x 42 columns]\n",
            "\n",
            "Combined Dataset Shape: (20000, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Function to preprocess the data\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset by:\n",
        "    1. Removing rows containing NaN values (invalid computations or uniform features).\n",
        "    2. Normalizing features using StandardScaler (to ensure zero mean and unit variance).\n",
        "    3. Reducing dimensionality using PCA (retains 10 most important components).\n",
        "\n",
        "    Returns:\n",
        "    - X: Preprocessed features\n",
        "    - y: Labels (0 = clean, 1 = stego)\n",
        "    - scaler: Fitted StandardScaler object\n",
        "    - pca: Fitted PCA object\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Split dataset into features and labels\n",
        "    X = data.drop(columns=['label']).values  # Drop label column for features\n",
        "    y = data['label'].values  # Extract label column\n",
        "\n",
        "    # Step 2: Remove any row that contains NaN (can happen due to uniform images or divide by zero)\n",
        "    print(\"\\n🔍 Removing rows with NaN values...\")\n",
        "    nan_mask = ~np.isnan(X).any(axis=1)  # Mask where rows do not contain NaNs\n",
        "    X = X[nan_mask]\n",
        "    y = y[nan_mask]\n",
        "    print(f\"✅ Dataset shape after removing NaNs: {X.shape}\")\n",
        "    print(\"🧾 First 5 rows of X (after NaN removal):\")\n",
        "    print(X[:5])  # Show first 5 rows\n",
        "\n",
        "    # Step 3: Normalize the features to have mean=0 and std=1\n",
        "    print(\"\\n⚙️ Normalizing features with StandardScaler...\")\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    print(\"✅ First 5 rows after normalization:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    # Step 4: Apply PCA to reduce to top 10 most significant components\n",
        "    print(\"\\n📉 Applying PCA to reduce dimensionality to 10 components...\")\n",
        "    pca = PCA(n_components=10)\n",
        "    X = pca.fit_transform(X)\n",
        "    print(\"📊 Explained Variance Ratio of PCA:\")\n",
        "    print(pca.explained_variance_ratio_)\n",
        "    print(\"✅ First 5 rows of transformed features after PCA:\")\n",
        "    print(X[:5])\n",
        "\n",
        "    return X, y, scaler, pca\n",
        "\n",
        "# Run the preprocessing function\n",
        "X_processed, y_labels, scaler_model, pca_model = preprocess_data(full_dataset)"
      ],
      "metadata": {
        "id": "rWU7oshpR7MB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f526ff8-e4ae-44f0-b23a-680f4612ba5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Removing rows with NaN values...\n",
            "✅ Dataset shape after removing NaNs: (19358, 41)\n",
            "🧾 First 5 rows of X (after NaN removal):\n",
            "[[-3.17326879e-01  8.27515384e-01  7.60604845e-01  7.40965975e-01\n",
            "   7.21417838e-01  9.10647001e-01  8.61356432e-01  8.35196209e-01\n",
            "   8.15543437e-01  8.18339071e-01  7.58361024e-01  7.32744946e-01\n",
            "   7.12313450e-01  8.06705401e-01  7.59407793e-01  1.60797637e-01\n",
            "   2.14583946e-01  1.91990069e-01  1.82255482e-01  1.76242578e-01\n",
            "  -2.84393560e-01 -1.14700224e-01 -5.35871230e-02 -8.57756000e-04\n",
            "  -2.30281000e-04 -4.37930600e-03  3.93935000e-03 -2.54409068e-01\n",
            "  -1.58545180e-01 -4.41293100e-02 -6.17937400e-03 -1.58812800e-03\n",
            "  -4.25697300e-03 -2.38575000e-04 -2.66942911e-01 -1.06837230e-01\n",
            "  -5.97025860e-02 -1.51620180e-02 -6.72895500e-03 -4.32901300e-03\n",
            "   1.18994800e-03]\n",
            " [-5.03110538e-01  8.62969506e-01  8.02899468e-01  7.75813071e-01\n",
            "   7.50999908e-01  9.27451720e-01  8.89261157e-01  8.66067459e-01\n",
            "   8.48225700e-01  8.55546058e-01  8.02765823e-01  7.72049795e-01\n",
            "   7.45870955e-01  8.48025765e-01  8.03066584e-01  7.08126906e-01\n",
            "   8.05188830e-01  7.82544553e-01  7.65448756e-01  7.54554646e-01\n",
            "  -2.69756459e-01 -1.23925267e-01 -6.05388300e-02 -3.14690400e-03\n",
            "   1.97719500e-03  1.90780600e-03  7.21822100e-03 -2.40194334e-01\n",
            "  -1.53606882e-01 -5.73649240e-02 -1.11691540e-02 -8.87453800e-03\n",
            "   3.52904300e-03  9.31591500e-03 -2.48362298e-01 -1.07545294e-01\n",
            "  -7.25590790e-02 -1.85204300e-02 -1.48776580e-02  4.43737100e-03\n",
            "   8.62581800e-03]\n",
            " [-1.82988165e-01  8.87022247e-01  8.35196275e-01  8.13357348e-01\n",
            "   7.89932373e-01  9.11071858e-01  8.61290901e-01  8.24738856e-01\n",
            "   7.95830289e-01  8.56713081e-01  7.89673594e-01  7.51655418e-01\n",
            "   7.19077459e-01  8.21966254e-01  8.14040556e-01  8.52228748e-01\n",
            "   8.86904817e-01  7.98770882e-01  7.58311344e-01  7.24417266e-01\n",
            "  -1.84675668e-01 -1.41335345e-01 -1.04674125e-01  3.33780330e-02\n",
            "   2.05133560e-02 -1.27999090e-02 -1.56012500e-03 -1.38367688e-01\n",
            "  -1.37662126e-01 -1.39336163e-01  5.56987220e-02  3.50867070e-02\n",
            "  -2.44243430e-02  4.26144600e-03 -1.37704042e-01 -8.85728460e-02\n",
            "  -1.71083527e-01  6.48987580e-02  5.21694630e-02 -2.49687250e-02\n",
            "  -2.45669000e-04]\n",
            " [ 6.10712600e-03  9.32942963e-01  9.06989589e-01  8.97635368e-01\n",
            "   8.86992609e-01  9.70490171e-01  9.54651988e-01  9.44757616e-01\n",
            "   9.34638932e-01  9.34616049e-01  9.09627985e-01  8.96681399e-01\n",
            "   8.85960989e-01  9.36205196e-01  9.08038824e-01  9.56642926e-01\n",
            "   9.57538244e-01  8.66155804e-01  7.77389540e-01  7.30494262e-01\n",
            "  -1.51531938e-01 -1.51232997e-01 -9.97532870e-02  2.23439880e-02\n",
            "   1.14565820e-02 -1.15653500e-02 -9.77229600e-03 -1.41366361e-01\n",
            "  -1.36213940e-01 -1.13354946e-01  2.75866550e-02  1.58320820e-02\n",
            "  -9.27909000e-03 -1.55310710e-02 -1.30430947e-01 -9.92061870e-02\n",
            "  -1.36826681e-01  3.91266480e-02  2.57860400e-02 -1.32319900e-02\n",
            "  -2.27284610e-02]\n",
            " [-6.28374420e-02  8.42911712e-01  7.54166316e-01  6.97134807e-01\n",
            "   6.50434952e-01  8.56006610e-01  7.75904023e-01  7.32342295e-01\n",
            "   7.00387704e-01  7.74753406e-01  6.67524383e-01  6.07226568e-01\n",
            "   5.63755555e-01  7.17680051e-01  7.06948794e-01  9.89532533e-01\n",
            "   9.89825393e-01  9.66221156e-01  9.37431269e-01  9.08575756e-01\n",
            "  -1.38280886e-01 -2.10430188e-01 -6.56504700e-02 -7.09406500e-03\n",
            "  -8.08364400e-03 -7.93929600e-03 -6.08440200e-03 -1.42655499e-01\n",
            "  -1.67040442e-01 -8.02435790e-02 -4.59293500e-03 -6.10433900e-03\n",
            "  -1.53024560e-02 -1.07149920e-02 -1.29836173e-01 -1.47590131e-01\n",
            "  -9.29156990e-02 -5.46633200e-03 -6.11160500e-03 -1.63792950e-02\n",
            "  -1.51061280e-02]]\n",
            "\n",
            "⚙️ Normalizing features with StandardScaler...\n",
            "✅ First 5 rows after normalization:\n",
            "[[-4.88272545e-01 -1.24843254e-01 -6.92512840e-02  2.81218583e-02\n",
            "   8.11479657e-02  3.42350181e-01  3.58636454e-01  3.80188014e-01\n",
            "   4.04506139e-01  5.28887177e-02  1.18729460e-01  1.96164528e-01\n",
            "   2.47783051e-01  1.94005376e-01  1.68101451e-02 -7.28024259e+00\n",
            "  -7.27339814e+00 -5.05339646e+00 -4.26411698e+00 -3.79384445e+00\n",
            "  -2.84843326e+00  1.91783086e+00  7.30841389e-01 -3.84903320e-01\n",
            "  -2.20882400e-01  4.73651711e-01  1.83285553e-01 -2.26185187e+00\n",
            "   1.08630736e-02  1.10218498e+00 -5.37986985e-01 -3.38814610e-01\n",
            "   5.79372720e-01  2.33689578e-02 -2.41625949e+00  6.40252439e-01\n",
            "   9.98447674e-01 -6.67860538e-01 -4.49880428e-01  5.86409672e-01\n",
            "   3.22210751e-01]\n",
            " [-1.05536552e+00  1.05924181e-01  1.45508259e-01  1.91330648e-01\n",
            "   2.12534849e-01  4.57574024e-01  5.06030110e-01  5.30049513e-01\n",
            "   5.53978661e-01  2.63196527e-01  3.25469886e-01  3.67118993e-01\n",
            "   3.87751204e-01  3.99862689e-01  2.29837345e-01 -2.22753556e+00\n",
            "  -1.44462857e+00 -8.46104009e-01 -5.97137544e-01 -4.08892407e-01\n",
            "  -2.53920126e+00  1.66876241e+00  5.92396808e-01 -4.35938488e-01\n",
            "  -1.68809141e-01  8.75445580e-01  4.52897822e-01 -1.98722033e+00\n",
            "   1.31022944e-01  8.91815027e-01 -6.18724230e-01 -4.61977767e-01\n",
            "   9.76446056e-01  6.06919565e-01 -2.08738082e+00  6.23820437e-01\n",
            "   8.18372926e-01 -7.13178305e-01 -5.62488028e-01  1.00137836e+00\n",
            "   7.11367816e-01]\n",
            " [-7.82120420e-02  2.62481135e-01  3.09501860e-01  3.67171872e-01\n",
            "   3.85450918e-01  3.45263271e-01  3.58290317e-01  3.29423805e-01\n",
            "   3.14347940e-01  2.69792978e-01  2.64514920e-01  2.78414675e-01\n",
            "   2.75995692e-01  2.70034672e-01  2.83383366e-01 -8.97249692e-01\n",
            "  -6.38161043e-01 -7.30502632e-01 -6.42015878e-01 -5.85291261e-01\n",
            "  -7.41734412e-01  1.19870485e+00 -2.86566075e-01  3.78362855e-01\n",
            "   2.68449665e-01 -6.44883228e-02 -2.68920688e-01 -1.99088985e-02\n",
            "   5.18994631e-01 -4.11055040e-01  4.63232904e-01  2.81105000e-01\n",
            "  -4.49128236e-01  2.98212512e-01 -1.28718826e-01  1.06411298e+00\n",
            "  -5.61611886e-01  4.12464208e-01  3.64041681e-01 -3.90599121e-01\n",
            "   2.47077579e-01]\n",
            " [ 4.98989480e-01  5.61374613e-01  6.74047002e-01  7.61893821e-01\n",
            "   8.16537787e-01  7.52673021e-01  8.51426585e-01  9.12043273e-01\n",
            "   9.49190086e-01  7.10129696e-01  8.23000096e-01  9.09197888e-01\n",
            "   9.72065900e-01  8.39171034e-01  7.42035275e-01  6.66568289e-02\n",
            "   5.89310076e-02 -2.50431646e-01 -5.22056758e-01 -5.49721642e-01\n",
            "  -4.15204721e-02  9.31476519e-01 -1.88566640e-01  1.32365506e-01\n",
            "   5.48048772e-02  1.44093074e-02 -9.44184233e-01 -7.78438685e-02\n",
            "   5.54232246e-01  1.89650696e-03  8.36498741e-03 -4.43584854e-02\n",
            "   3.23253447e-01 -9.10636449e-01  1.56695410e-05  8.17345630e-01\n",
            "  -8.17926314e-02  6.47003021e-02 -5.53023286e-04  1.64975167e-01\n",
            "  -9.29561783e-01]\n",
            " [ 2.88540508e-01 -2.46300515e-02 -1.01944223e-01 -1.77164456e-01\n",
            "  -2.34118011e-01 -3.22990969e-02 -9.27259215e-02 -1.19106368e-01\n",
            "  -1.22159284e-01 -1.93473766e-01 -3.04188926e-01 -3.49771345e-01\n",
            "  -3.71851043e-01 -2.49517322e-01 -2.39156486e-01  3.70279452e-01\n",
            "   3.77577800e-01  4.62464813e-01  4.84247251e-01  4.92617521e-01\n",
            "   2.38429048e-01 -6.66798167e-01  4.90597515e-01 -5.23938051e-01\n",
            "  -4.06139322e-01  2.46141503e-01 -6.40939162e-01 -1.02750276e-01\n",
            "  -1.95845711e-01  5.28176327e-01 -5.12317574e-01 -4.15152725e-01\n",
            "   1.60722090e-02 -6.16489318e-01  1.05432277e-02 -3.05497869e-01\n",
            "   5.33247488e-01 -5.37028812e-01 -4.41349217e-01  1.59932110e-02\n",
            "  -5.30646157e-01]]\n",
            "\n",
            "📉 Applying PCA to reduce dimensionality to 10 components...\n",
            "📊 Explained Variance Ratio of PCA:\n",
            "[0.34933847 0.25325881 0.11328639 0.10396695 0.0582953  0.03268833\n",
            " 0.01998358 0.01416521 0.01266699 0.00843501]\n",
            "✅ First 5 rows of transformed features after PCA:\n",
            "[[ 0.44492168  3.4831905  -8.31895093 -7.87979839 -3.35021102  4.92507816\n",
            "  -1.56227855  0.15574811 -3.23956005 -0.36786936]\n",
            " [-0.06416316  3.50923528 -1.97823227 -0.66285506 -1.30694438  3.94204032\n",
            "  -0.19250202  0.2925629  -1.19120085 -0.2445733 ]\n",
            " [ 1.84034872 -0.54231711 -1.16594215 -0.66919508 -0.09695839  1.62184587\n",
            "  -0.06653646 -0.32517368 -0.2843512   0.20576922]\n",
            " [ 2.85638727  0.97171063 -1.76104404  0.93577446  0.74084318  0.0434043\n",
            "   0.17426312 -0.78725354  0.23751208 -0.15259115]\n",
            " [-1.4111086   0.80276462  0.11114373  0.7112215   0.60683278 -1.23804523\n",
            "   0.02433064 -0.5021851  -0.32250499  0.08020079]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Run the preprocessing function (from Step 2) to get X and y\n",
        "X, y, scaler, pca = preprocess_data(full_dataset)\n",
        "\n",
        "# Split the preprocessed dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "def train_classifier(X_train, y_train):\n",
        "    \"\"\"\n",
        "    This function trains a Random Forest Classifier on the training data.\n",
        "    Returns the trained classifier and prints training accuracy and classification report.\n",
        "    \"\"\"\n",
        "    print(\"\\nTraining Random Forest Classifier...\")\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=100,  # Number of trees in the forest\n",
        "        max_depth=10,      # Maximum depth of each tree\n",
        "        random_state=42,   # For reproducibility\n",
        "        n_jobs=-1          # Use all available CPU cores for faster training\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # 1. Training Accuracy\n",
        "    train_preds = clf.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, train_preds)\n",
        "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # 2. Classification Report\n",
        "    print(\"\\nClassification Report on Training Data:\")\n",
        "    print(classification_report(y_train, train_preds, target_names=[\"Cover\", \"Stego\"]))\n",
        "\n",
        "    return clf\n",
        "\n",
        "# Run the function\n",
        "clf = train_classifier(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "1vJ1ji3o-Eyj",
        "outputId": "b0c9d141-37e1-4001-8694-afcd60bb7412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Removing rows with NaN values...\n",
            "✅ Dataset shape after removing NaNs: (19358, 41)\n",
            "🧾 First 5 rows of X (after NaN removal):\n",
            "[[-3.17326879e-01  8.27515384e-01  7.60604845e-01  7.40965975e-01\n",
            "   7.21417838e-01  9.10647001e-01  8.61356432e-01  8.35196209e-01\n",
            "   8.15543437e-01  8.18339071e-01  7.58361024e-01  7.32744946e-01\n",
            "   7.12313450e-01  8.06705401e-01  7.59407793e-01  1.60797637e-01\n",
            "   2.14583946e-01  1.91990069e-01  1.82255482e-01  1.76242578e-01\n",
            "  -2.84393560e-01 -1.14700224e-01 -5.35871230e-02 -8.57756000e-04\n",
            "  -2.30281000e-04 -4.37930600e-03  3.93935000e-03 -2.54409068e-01\n",
            "  -1.58545180e-01 -4.41293100e-02 -6.17937400e-03 -1.58812800e-03\n",
            "  -4.25697300e-03 -2.38575000e-04 -2.66942911e-01 -1.06837230e-01\n",
            "  -5.97025860e-02 -1.51620180e-02 -6.72895500e-03 -4.32901300e-03\n",
            "   1.18994800e-03]\n",
            " [-5.03110538e-01  8.62969506e-01  8.02899468e-01  7.75813071e-01\n",
            "   7.50999908e-01  9.27451720e-01  8.89261157e-01  8.66067459e-01\n",
            "   8.48225700e-01  8.55546058e-01  8.02765823e-01  7.72049795e-01\n",
            "   7.45870955e-01  8.48025765e-01  8.03066584e-01  7.08126906e-01\n",
            "   8.05188830e-01  7.82544553e-01  7.65448756e-01  7.54554646e-01\n",
            "  -2.69756459e-01 -1.23925267e-01 -6.05388300e-02 -3.14690400e-03\n",
            "   1.97719500e-03  1.90780600e-03  7.21822100e-03 -2.40194334e-01\n",
            "  -1.53606882e-01 -5.73649240e-02 -1.11691540e-02 -8.87453800e-03\n",
            "   3.52904300e-03  9.31591500e-03 -2.48362298e-01 -1.07545294e-01\n",
            "  -7.25590790e-02 -1.85204300e-02 -1.48776580e-02  4.43737100e-03\n",
            "   8.62581800e-03]\n",
            " [-1.82988165e-01  8.87022247e-01  8.35196275e-01  8.13357348e-01\n",
            "   7.89932373e-01  9.11071858e-01  8.61290901e-01  8.24738856e-01\n",
            "   7.95830289e-01  8.56713081e-01  7.89673594e-01  7.51655418e-01\n",
            "   7.19077459e-01  8.21966254e-01  8.14040556e-01  8.52228748e-01\n",
            "   8.86904817e-01  7.98770882e-01  7.58311344e-01  7.24417266e-01\n",
            "  -1.84675668e-01 -1.41335345e-01 -1.04674125e-01  3.33780330e-02\n",
            "   2.05133560e-02 -1.27999090e-02 -1.56012500e-03 -1.38367688e-01\n",
            "  -1.37662126e-01 -1.39336163e-01  5.56987220e-02  3.50867070e-02\n",
            "  -2.44243430e-02  4.26144600e-03 -1.37704042e-01 -8.85728460e-02\n",
            "  -1.71083527e-01  6.48987580e-02  5.21694630e-02 -2.49687250e-02\n",
            "  -2.45669000e-04]\n",
            " [ 6.10712600e-03  9.32942963e-01  9.06989589e-01  8.97635368e-01\n",
            "   8.86992609e-01  9.70490171e-01  9.54651988e-01  9.44757616e-01\n",
            "   9.34638932e-01  9.34616049e-01  9.09627985e-01  8.96681399e-01\n",
            "   8.85960989e-01  9.36205196e-01  9.08038824e-01  9.56642926e-01\n",
            "   9.57538244e-01  8.66155804e-01  7.77389540e-01  7.30494262e-01\n",
            "  -1.51531938e-01 -1.51232997e-01 -9.97532870e-02  2.23439880e-02\n",
            "   1.14565820e-02 -1.15653500e-02 -9.77229600e-03 -1.41366361e-01\n",
            "  -1.36213940e-01 -1.13354946e-01  2.75866550e-02  1.58320820e-02\n",
            "  -9.27909000e-03 -1.55310710e-02 -1.30430947e-01 -9.92061870e-02\n",
            "  -1.36826681e-01  3.91266480e-02  2.57860400e-02 -1.32319900e-02\n",
            "  -2.27284610e-02]\n",
            " [-6.28374420e-02  8.42911712e-01  7.54166316e-01  6.97134807e-01\n",
            "   6.50434952e-01  8.56006610e-01  7.75904023e-01  7.32342295e-01\n",
            "   7.00387704e-01  7.74753406e-01  6.67524383e-01  6.07226568e-01\n",
            "   5.63755555e-01  7.17680051e-01  7.06948794e-01  9.89532533e-01\n",
            "   9.89825393e-01  9.66221156e-01  9.37431269e-01  9.08575756e-01\n",
            "  -1.38280886e-01 -2.10430188e-01 -6.56504700e-02 -7.09406500e-03\n",
            "  -8.08364400e-03 -7.93929600e-03 -6.08440200e-03 -1.42655499e-01\n",
            "  -1.67040442e-01 -8.02435790e-02 -4.59293500e-03 -6.10433900e-03\n",
            "  -1.53024560e-02 -1.07149920e-02 -1.29836173e-01 -1.47590131e-01\n",
            "  -9.29156990e-02 -5.46633200e-03 -6.11160500e-03 -1.63792950e-02\n",
            "  -1.51061280e-02]]\n",
            "\n",
            "⚙️ Normalizing features with StandardScaler...\n",
            "✅ First 5 rows after normalization:\n",
            "[[-4.88272545e-01 -1.24843254e-01 -6.92512840e-02  2.81218583e-02\n",
            "   8.11479657e-02  3.42350181e-01  3.58636454e-01  3.80188014e-01\n",
            "   4.04506139e-01  5.28887177e-02  1.18729460e-01  1.96164528e-01\n",
            "   2.47783051e-01  1.94005376e-01  1.68101451e-02 -7.28024259e+00\n",
            "  -7.27339814e+00 -5.05339646e+00 -4.26411698e+00 -3.79384445e+00\n",
            "  -2.84843326e+00  1.91783086e+00  7.30841389e-01 -3.84903320e-01\n",
            "  -2.20882400e-01  4.73651711e-01  1.83285553e-01 -2.26185187e+00\n",
            "   1.08630736e-02  1.10218498e+00 -5.37986985e-01 -3.38814610e-01\n",
            "   5.79372720e-01  2.33689578e-02 -2.41625949e+00  6.40252439e-01\n",
            "   9.98447674e-01 -6.67860538e-01 -4.49880428e-01  5.86409672e-01\n",
            "   3.22210751e-01]\n",
            " [-1.05536552e+00  1.05924181e-01  1.45508259e-01  1.91330648e-01\n",
            "   2.12534849e-01  4.57574024e-01  5.06030110e-01  5.30049513e-01\n",
            "   5.53978661e-01  2.63196527e-01  3.25469886e-01  3.67118993e-01\n",
            "   3.87751204e-01  3.99862689e-01  2.29837345e-01 -2.22753556e+00\n",
            "  -1.44462857e+00 -8.46104009e-01 -5.97137544e-01 -4.08892407e-01\n",
            "  -2.53920126e+00  1.66876241e+00  5.92396808e-01 -4.35938488e-01\n",
            "  -1.68809141e-01  8.75445580e-01  4.52897822e-01 -1.98722033e+00\n",
            "   1.31022944e-01  8.91815027e-01 -6.18724230e-01 -4.61977767e-01\n",
            "   9.76446056e-01  6.06919565e-01 -2.08738082e+00  6.23820437e-01\n",
            "   8.18372926e-01 -7.13178305e-01 -5.62488028e-01  1.00137836e+00\n",
            "   7.11367816e-01]\n",
            " [-7.82120420e-02  2.62481135e-01  3.09501860e-01  3.67171872e-01\n",
            "   3.85450918e-01  3.45263271e-01  3.58290317e-01  3.29423805e-01\n",
            "   3.14347940e-01  2.69792978e-01  2.64514920e-01  2.78414675e-01\n",
            "   2.75995692e-01  2.70034672e-01  2.83383366e-01 -8.97249692e-01\n",
            "  -6.38161043e-01 -7.30502632e-01 -6.42015878e-01 -5.85291261e-01\n",
            "  -7.41734412e-01  1.19870485e+00 -2.86566075e-01  3.78362855e-01\n",
            "   2.68449665e-01 -6.44883228e-02 -2.68920688e-01 -1.99088985e-02\n",
            "   5.18994631e-01 -4.11055040e-01  4.63232904e-01  2.81105000e-01\n",
            "  -4.49128236e-01  2.98212512e-01 -1.28718826e-01  1.06411298e+00\n",
            "  -5.61611886e-01  4.12464208e-01  3.64041681e-01 -3.90599121e-01\n",
            "   2.47077579e-01]\n",
            " [ 4.98989480e-01  5.61374613e-01  6.74047002e-01  7.61893821e-01\n",
            "   8.16537787e-01  7.52673021e-01  8.51426585e-01  9.12043273e-01\n",
            "   9.49190086e-01  7.10129696e-01  8.23000096e-01  9.09197888e-01\n",
            "   9.72065900e-01  8.39171034e-01  7.42035275e-01  6.66568289e-02\n",
            "   5.89310076e-02 -2.50431646e-01 -5.22056758e-01 -5.49721642e-01\n",
            "  -4.15204721e-02  9.31476519e-01 -1.88566640e-01  1.32365506e-01\n",
            "   5.48048772e-02  1.44093074e-02 -9.44184233e-01 -7.78438685e-02\n",
            "   5.54232246e-01  1.89650696e-03  8.36498741e-03 -4.43584854e-02\n",
            "   3.23253447e-01 -9.10636449e-01  1.56695410e-05  8.17345630e-01\n",
            "  -8.17926314e-02  6.47003021e-02 -5.53023286e-04  1.64975167e-01\n",
            "  -9.29561783e-01]\n",
            " [ 2.88540508e-01 -2.46300515e-02 -1.01944223e-01 -1.77164456e-01\n",
            "  -2.34118011e-01 -3.22990969e-02 -9.27259215e-02 -1.19106368e-01\n",
            "  -1.22159284e-01 -1.93473766e-01 -3.04188926e-01 -3.49771345e-01\n",
            "  -3.71851043e-01 -2.49517322e-01 -2.39156486e-01  3.70279452e-01\n",
            "   3.77577800e-01  4.62464813e-01  4.84247251e-01  4.92617521e-01\n",
            "   2.38429048e-01 -6.66798167e-01  4.90597515e-01 -5.23938051e-01\n",
            "  -4.06139322e-01  2.46141503e-01 -6.40939162e-01 -1.02750276e-01\n",
            "  -1.95845711e-01  5.28176327e-01 -5.12317574e-01 -4.15152725e-01\n",
            "   1.60722090e-02 -6.16489318e-01  1.05432277e-02 -3.05497869e-01\n",
            "   5.33247488e-01 -5.37028812e-01 -4.41349217e-01  1.59932110e-02\n",
            "  -5.30646157e-01]]\n",
            "\n",
            "📉 Applying PCA to reduce dimensionality to 10 components...\n",
            "📊 Explained Variance Ratio of PCA:\n",
            "[0.34933847 0.25325881 0.11328639 0.10396695 0.0582953  0.03268833\n",
            " 0.01998358 0.01416521 0.01266699 0.00843501]\n",
            "✅ First 5 rows of transformed features after PCA:\n",
            "[[ 0.44492168  3.4831905  -8.31895093 -7.87979839 -3.35021102  4.92507816\n",
            "  -1.56227855  0.15574811 -3.23956005 -0.36786936]\n",
            " [-0.06416316  3.50923528 -1.97823227 -0.66285506 -1.30694438  3.94204032\n",
            "  -0.19250202  0.2925629  -1.19120085 -0.2445733 ]\n",
            " [ 1.84034872 -0.54231711 -1.16594215 -0.66919508 -0.09695839  1.62184587\n",
            "  -0.06653646 -0.32517368 -0.2843512   0.20576922]\n",
            " [ 2.85638727  0.97171063 -1.76104404  0.93577446  0.74084318  0.0434043\n",
            "   0.17426312 -0.78725354  0.23751208 -0.15259115]\n",
            " [-1.4111086   0.80276462  0.11114373  0.7112215   0.60683278 -1.23804523\n",
            "   0.02433064 -0.5021851  -0.32250499  0.08020079]]\n",
            "\n",
            "Training Random Forest Classifier...\n",
            "Training Accuracy: 0.7801\n",
            "\n",
            "Classification Report on Training Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Cover       0.90      0.63      0.74      6759\n",
            "       Stego       0.72      0.93      0.81      6791\n",
            "\n",
            "    accuracy                           0.78     13550\n",
            "   macro avg       0.81      0.78      0.78     13550\n",
            "weighted avg       0.81      0.78      0.78     13550\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract CF features from an image\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from scipy.stats import pearsonr\n",
        "import pywt\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def getPlaneBits(planeId, binary_image):\n",
        "    return [int(b[planeId]) for b in binary_image]\n",
        "\n",
        "def getBitPlanes(img):\n",
        "    bin_image = []\n",
        "    bit_planes = []\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            bin_image.append(np.binary_repr(img[i][j], width=8))\n",
        "    for i in range(8):\n",
        "        bit_planes.append(np.array(getPlaneBits(i, bin_image)).reshape(img.shape))\n",
        "    return bit_planes\n",
        "\n",
        "def autocor(A, k, l):\n",
        "    Xk = A[0:A.shape[0] - k, 0:A.shape[1] - l]\n",
        "    Xl = A[k:A.shape[0], l:A.shape[1]]\n",
        "    return pearsonr(Xk.flatten(), Xl.flatten())\n",
        "\n",
        "def getHl1(img_hist, l):\n",
        "    return img_hist[0:256 - l]\n",
        "\n",
        "def getHl2(img_hist, l):\n",
        "    return img_hist[l:256]\n",
        "\n",
        "def getCHl(img_hist, l):\n",
        "    return pearsonr(getHl1(img_hist, l), getHl2(img_hist, l))\n",
        "\n",
        "def getModifiedWavelet(C, t):\n",
        "    for i, row in enumerate(C):\n",
        "        for j, val in enumerate(row):\n",
        "            if abs(val) < t:\n",
        "                C[i][j] = 0\n",
        "    return C\n",
        "\n",
        "def getE(img, t):\n",
        "    coeffs = pywt.dwt2(img, 'haar')\n",
        "    LL, (LH, HL, HH) = coeffs\n",
        "    LH = getModifiedWavelet(LH, t)\n",
        "    HL = getModifiedWavelet(HL, t)\n",
        "    HH = getModifiedWavelet(HH, t)\n",
        "    img_denoised = pywt.idwt2((LL, (LH, HL, HH)), 'haar')\n",
        "    E = img - img_denoised\n",
        "    return E\n",
        "\n",
        "def getCE(img, t, k, l):\n",
        "    E = getE(img, t)\n",
        "    return autocor(E, k, l)\n",
        "\n",
        "# --- Main CF Extraction Function ---\n",
        "def extract_cf_features(image_array, scaler, pca):\n",
        "    \"\"\"\n",
        "    Extracts 41 correlation features (CF) from a given grayscale image array.\n",
        "    Features are normalized and reduced using a pre-trained scaler and PCA model.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    bit_planes = getBitPlanes(image_array)\n",
        "\n",
        "    # Bit plane correlation\n",
        "    M1 = bit_planes[0]  # LSB\n",
        "    M2 = bit_planes[1]  # Second LSB\n",
        "    features.append(pearsonr(M1.flatten(), M2.flatten())[0])\n",
        "\n",
        "    # Autocorrelation on LSB\n",
        "    autocor_kl_pairs = [[1, 0], [2, 0], [3, 0], [4, 0], [0, 1], [0, 2], [0, 3], [0, 4],\n",
        "                        [1, 1], [2, 2], [3, 3], [4, 4], [1, 2], [2, 1]]\n",
        "    for k, l in autocor_kl_pairs:\n",
        "        features.append(autocor(M1, k, l)[0])\n",
        "\n",
        "    # Histogram even vs odd correlation\n",
        "    img_hist, _ = np.histogram(image_array.flatten(), bins=256, density=True)\n",
        "    He = [img_hist[i] for i in range(0, 256, 2)]\n",
        "    Ho = [img_hist[i] for i in range(1, 256, 2)]\n",
        "    features.append(pearsonr(He, Ho)[0])\n",
        "\n",
        "    # Histogram shifts\n",
        "    for i in range(1, 5):\n",
        "        features.append(getCHl(img_hist, i)[0])\n",
        "\n",
        "    # Wavelet residual correlations\n",
        "    autocor_tkl_triplets = [[1.5, 0, 1], [1.5, 1, 0], [1.5, 1, 1], [1.5, 0, 2], [1.5, 2, 0], [1.5, 1, 2], [1.5, 2, 1],\n",
        "                            [2, 0, 1], [2, 1, 0], [2, 1, 1], [2, 0, 2], [2, 2, 0], [2, 1, 2], [2, 2, 1],\n",
        "                            [2.5, 0, 1], [2.5, 1, 0], [2.5, 1, 1], [2.5, 0, 2], [2.5, 2, 0], [2.5, 1, 2], [2.5, 2, 1]]\n",
        "    for t, k, l in autocor_tkl_triplets:\n",
        "        features.append(getCE(image_array, t, k, l)[0])\n",
        "\n",
        "    # Convert to NumPy array and normalize\n",
        "    features = np.array(features)\n",
        "    features = scaler.transform(features.reshape(1, -1))\n",
        "    features = pca.transform(features)\n",
        "\n",
        "    print(\"\\nExtracted CF Feature Vector (41 values):\")\n",
        "    print(features)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "39YYobtXSBtv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Prediction Function Using Extracted Features ---\n",
        "def run_prediction(scaler, pca, clf):\n",
        "    \"\"\"\n",
        "    Asks user for an image URL, downloads it, extracts features, and predicts stego/cover.\n",
        "    \"\"\"\n",
        "    image_url = input(\"\\nEnter the URL of the image to test (must be 512x512 grayscale .pgm): \")\n",
        "    print(\"\\nDownloading and processing image...\")\n",
        "\n",
        "    try:\n",
        "        resp = requests.get(image_url).content\n",
        "        image_array = np.asarray(bytearray(resp), dtype=np.uint8)\n",
        "        image = cv2.imdecode(image_array, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if image is None or image.shape != (512, 512):\n",
        "            raise ValueError(\"The input image must be a 512x512 grayscale image.\")\n",
        "\n",
        "        print(\"Extracting CF features and making prediction...\")\n",
        "        features = extract_cf_features(image, scaler, pca)\n",
        "        prediction = clf.predict(features)\n",
        "        result = \"Steg Image (LSB Matching Detected)\" if prediction[0] == 1 else \"Cover Image (No LSB Matching)\"\n",
        "        print(\"\\nPrediction Result:\", result)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\nError processing the image:\", e)\n",
        "        return None\n",
        "\n",
        "# Run the function to test prediction (example)\n",
        "# Uncomment the following line after training classifier and preprocessing pipeline:\n",
        "run_prediction(scaler, pca, clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "iu2Nqf55SGII",
        "outputId": "f95dd624-12b0-4319-a187-d4e89bfee2fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the URL of the image to test (must be 512x512 grayscale .pgm): https://raw.githubusercontent.com/Sourish1997/steganalysis/master/bossbase_sample/10.pgm\n",
            "\n",
            "Downloading and processing image...\n",
            "Extracting CF features and making prediction...\n",
            "\n",
            "Extracted CF Feature Vector (41 values):\n",
            "[[ 0.64193957  2.3636459   0.58906108  0.89164574 -0.56640136 -1.21387322\n",
            "   1.15298357 -0.15932857 -0.09841518 -0.30340162]]\n",
            "\n",
            "Prediction Result: Steg Image (LSB Matching Detected)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Steg Image (LSB Matching Detected)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Explanation of the Process:\n",
        "1. Input : The user provided the path to the link to the image for testing.\n",
        "2. Feature Extraction : The program extracted features from the image using the CF (Correlation Features) feature set described in the project report. These features capture spatial information from the image, particularly focusing on the least significant bit planes.\n",
        "3. Preprocessing : The extracted features were preprocessed to ensure compatibility with the trained model. This includes:\n",
        "\n",
        "  3.1 Normalization using StandardScaler.\n",
        "\n",
        "  3.2 Dimensionality reduction using Principal Component Analysis (PCA).\n",
        "4. Prediction : The preprocessed features were passed to the trained voting ensemble model, which consists of parameter-tuned versions of MLP Classifier and AdaBoost models.\n",
        "5. Output : The model predicted that the image does not contain LSB matching steganography, classifying it as a Cover Image .\n",
        "\n",
        "Key Points from the Output:\n",
        "1. Prediction : The model classified the image as a Cover Image , meaning no signs of LSB matching steganography were detected.\n",
        "2. Confidence : While the exact confidence score is not provided in the output, the model's accuracy and F-score (as reported in the project) suggest a reliable prediction. The final model achieved an accuracy of 75.52% and an F-score of 79.30% , which is significantly better than the benchmark Gaussian Naïve Bayes model.\n",
        "\n",
        " Possible Scenarios:\n",
        "1. True Negative : If the image is indeed a clean image without any steganography, the prediction is correct.\n",
        "2. False Negative : If the image contains LSB matching steganography but was misclassified as a cover image, this would indicate a limitation of the model. However, given the high F-score of the model, such cases are less likely but not impossible.\n",
        "\n",
        " Limitations to Consider:\n",
        "1. Image Size : The feature extraction process is designed for 512x512 grayscale images. If the input image does not meet this requirement, it may have been cropped or resampled, potentially affecting the prediction.\n",
        "2. Overly Uniform Images : If the image is overly dark or bright, some CF features may result in NaN values, making it unsuitable for analysis. However, since the program completed the prediction, this issue likely did not occur here."
      ],
      "metadata": {
        "id": "YE7SrnA72tsO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}